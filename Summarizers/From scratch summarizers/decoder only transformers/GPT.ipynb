{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJpXpmjEYC_T"
      },
      "source": [
        "## Building a GPT then extending it to make an Abstractive Summarizer maybe :)\n",
        "## Note this notebook uses character tokenization and tinyshakespeare dataset \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5hjCcLDr2WC",
        "outputId": "7d135749-87dd-4de6-917e-71bc953157e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-04-25 13:54:33--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-04-25 13:54:33 (20.1 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "O6medjfRsLD9"
      },
      "outputs": [],
      "source": [
        "# read it in to inspect it\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xWI_VyAsN8F",
        "outputId": "cf3e5a55-000d-4e02-b922-93d2fb5a10a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of dataset in characters:  1115394\n"
          ]
        }
      ],
      "source": [
        "print(\"length of dataset in characters: \", len(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c5V0FvqseE0",
        "outputId": "8f4e73a5-349c-42da-d8c9-c9721f16308e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# let's look at the first 1000 characters\n",
        "print(text[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e-Rbyr8sfM8",
        "outputId": "39b0e471-5a7c-44cf-b2d4-a264a2580f92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ],
      "source": [
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJTEsSMEYD14"
      },
      "source": [
        "## Tokenization process where here we use character tokenization instead of word tokenization\n",
        "\n",
        "#(May change that later to subword tokenizer if we changed our dataset to a larger one)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw1LKNCgwjj1",
        "outputId": "181be49d-be1f-4076-9a16-c19931a2f881"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
            "hii there\n"
          ]
        }
      ],
      "source": [
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "print(encode(\"hii there\"))\n",
        "print(decode(encode(\"hii there\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-cZcfClZBqJ"
      },
      "source": [
        "## Import Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IRbbq_64N4b",
        "outputId": "e146a245-5be8-4a7a-ae65-1c70ceb7a70b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBh56_7Y4Rjg"
      },
      "source": [
        "### let's now encode the entire text dataset and store it into a torch.Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJb0OXPwzvqg",
        "outputId": "b92b5de1-d7ad-4132-9eb5-94ad6d4dbc7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1115394]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
            "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
            "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
            "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
            "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
            "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
            "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
            "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
            "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
            "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
            "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
            "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
            "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
            "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
            "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
            "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
            "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
            "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
            "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
            "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
            "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
            "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
            "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
            "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
            "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
            "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
            "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
            "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
            "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
            "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
            "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
            "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
            "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
            "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
            "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
            "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
            "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
            "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
            "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
            "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
            "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
            "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
            "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
            "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
            "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
            "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
            "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
            "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
            "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
          ]
        }
      ],
      "source": [
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-31mtcVbV7N"
      },
      "source": [
        "## Let's now split up the data into train and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "f_WIXqxz0lU5"
      },
      "outputs": [],
      "source": [
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH6GDWf6bZVj"
      },
      "source": [
        "Important thing to realize is we're never going to actually feed the entire text into Transformer all at once that would be computationally very expensive and prohibitive so when we\n",
        "actually train a Transformer on a lot of these data sets we only work with chunks of the data set and when we train the\n",
        "Transformer we basically sample random little chunks out of the training set and train them just chunks at a time and\n",
        "these chunks have basically some kind of a length as a maximum length "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD5Bj8Y6IAD4",
        "outputId": "433727a5-17fe-4698-be11-cfd79680baa7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]\n",
        "# why +1 ?\n",
        "# because we are predicting the next token based on all previous tokens\n",
        "# by using 9 tokens we make 8 predictions since the first token is given as initialization for the sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5XYiUJ_ZTqv"
      },
      "source": [
        "## Language Modeling task where we predict next word given the previous words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HXDe8vGJCEn",
        "outputId": "062a8aff-620f-41f2-f0c3-a21f38701e91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "when input is tensor([18]) the target: 47\n",
            "when input is tensor([18, 47]) the target: 56\n",
            "when input is tensor([18, 47, 56]) the target: 57\n",
            "when input is tensor([18, 47, 56, 57]) the target: 58\n",
            "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
            "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
          ]
        }
      ],
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "# These are the eight examples hidden in a chunk of nine characters that we sampled from the training set \n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context} the target: {target}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP67doT-deoi"
      },
      "source": [
        "## Important note \n",
        "while we're sampling we can start the sampling generation with as little as one character of context and the Transformer knows how to predict the next character with all the way up to just one context of one and so then it can predict everything up to block size and after block size we have to start truncating because the Transformer will never receive more than block size inputs when it's predicting the next character.\n",
        "# Therefore Take care of block size , since if the input prompt is larger than it, We will truncate :("
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juLd496Jd3TP"
      },
      "source": [
        "## Batch Dimension\n",
        "\n",
        "Okay so we've looked at the time dimension of the tensors that are going to be feeding into the Transformer there's one more Dimension to care about and that is the batch dimension \n",
        "\n",
        "---\n",
        "\n",
        "so as we're sampling these chunks of text we're going to be actually every time\n",
        "we're going to feed them into a Transformer we're going to have many batches of multiple chunks of text that are all like stacked up in a single\n",
        "tensor and that's just done for efficiency just so that we can keep the gpus busy because they are very good at\n",
        "parallel processing of data and so we just want to process multiple chunks all at the same\n",
        "time but those chunks are processed completely independently they don't talk to each other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3k1Czf7LuA9",
        "outputId": "28f3cfcf-2ffd-45c9-893d-b6fc7cb4d067"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]], device='cuda:0')\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
            "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
            "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
            "        [17, 27, 10,  0, 21,  1, 54, 39]], device='cuda:0')\n",
            "----\n",
            "when input is [24] the target: 43\n",
            "when input is [24, 43] the target: 58\n",
            "when input is [24, 43, 58] the target: 5\n",
            "when input is [24, 43, 58, 5] the target: 57\n",
            "when input is [24, 43, 58, 5, 57] the target: 1\n",
            "when input is [24, 43, 58, 5, 57, 1] the target: 46\n",
            "when input is [24, 43, 58, 5, 57, 1, 46] the target: 43\n",
            "when input is [24, 43, 58, 5, 57, 1, 46, 43] the target: 39\n",
            "when input is [44] the target: 53\n",
            "when input is [44, 53] the target: 56\n",
            "when input is [44, 53, 56] the target: 1\n",
            "when input is [44, 53, 56, 1] the target: 58\n",
            "when input is [44, 53, 56, 1, 58] the target: 46\n",
            "when input is [44, 53, 56, 1, 58, 46] the target: 39\n",
            "when input is [44, 53, 56, 1, 58, 46, 39] the target: 58\n",
            "when input is [44, 53, 56, 1, 58, 46, 39, 58] the target: 1\n",
            "when input is [52] the target: 58\n",
            "when input is [52, 58] the target: 1\n",
            "when input is [52, 58, 1] the target: 58\n",
            "when input is [52, 58, 1, 58] the target: 46\n",
            "when input is [52, 58, 1, 58, 46] the target: 39\n",
            "when input is [52, 58, 1, 58, 46, 39] the target: 58\n",
            "when input is [52, 58, 1, 58, 46, 39, 58] the target: 1\n",
            "when input is [52, 58, 1, 58, 46, 39, 58, 1] the target: 46\n",
            "when input is [25] the target: 17\n",
            "when input is [25, 17] the target: 27\n",
            "when input is [25, 17, 27] the target: 10\n",
            "when input is [25, 17, 27, 10] the target: 0\n",
            "when input is [25, 17, 27, 10, 0] the target: 21\n",
            "when input is [25, 17, 27, 10, 0, 21] the target: 1\n",
            "when input is [25, 17, 27, 10, 0, 21, 1] the target: 54\n",
            "when input is [25, 17, 27, 10, 0, 21, 1, 54] the target: 39\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4 # how many independent sequences will we process in parallel?\n",
        "block_size = 8 # what is the maximum context length for predictions?\n",
        "\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    # generate batch_size(4) random numbers between (0, (len(data) - block_size))\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    # stack the independent sequences over each other to build the batch\n",
        "    # where each stack start from a value from ix generated random numbers\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('----')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpyyAeIzQjlO",
        "outputId": "3139803c-4b7a-41a3-f84f-9a692b83b90b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "print(xb) # our input to the transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqDxsr-IhD60"
      },
      "source": [
        "## Simplest Possible Neural Network : Bigram Language Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nql_1ER53oCf",
        "outputId": "5fbbef2c-16ae-40bc-b15a-fc230a20e6a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.8786, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        # A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "        # so what's happening here is that when we pass idx here every single integer in our input is going to refer to this\n",
        "        # embedding table and is going to get a row of that embedding table corresponding to its index\n",
        "    \n",
        "    def forward(self, idx, targets=None):\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        # Pi torch is going to arrange all of this into a batch by Time by Channel tensor\n",
        "        # in this case batch is 4, time is 8 and C which is the channels is vocab size 65.\n",
        "        # logits which are basically the scores for the next character in the sequence\n",
        "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            # since pytorch cross_entropy function expects input to be in shape (minibatch, C)\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            # to measure a loss or like a quality of the predictions use the \n",
        "            # negative log likelihood loss which is implemented in pytorch under the name cross_entropy\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "    \n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # get the predictions\n",
        "            # call to the forward method of the BigramLanguageModel class.\n",
        "            logits, loss = self(idx)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            \n",
        "            # If you want to get most probable next token instead of sampling\n",
        "            # idx_next = torch.argmax(probs, dim=1).view(-1,1) # (B, 1)\n",
        "\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "m = BigramLanguageModel(vocab_size).to(device)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "generated = m.generate(idx = torch.zeros((2, 1), dtype=torch.long, device=device), max_new_tokens=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VuBNAHSuV1T",
        "outputId": "628e673d-1b61-46e2-bd02-dc747e76ac36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "pYCXxfRkRZd\n",
            "wc'wfNfT;OLlTEeC K\n",
            "jxqPToTb?bXAUG:C-SGJO-33SM:C?YI3a\n",
            "hs:LVXJFhXeNuwqhObxZ.tSVrddXlaSZaNe\n",
            "\n",
            "!X:.yvvVwfMgFlxnAUe!$gm CXtgfFkzwQJ&yQ&QJs$FJdpxO CPbL-kobMtOiGvWmtxfk&ufNCeYS$SVws-!wfF.WT;nphaPbxu\n"
          ]
        }
      ],
      "source": [
        "# They are not the same although they start with same token ' ', because we sample from distribution\n",
        "# instead if we used argmax to get most probable token, they will be the same output\n",
        "print(decode(generated[0].tolist()))\n",
        "print(decode(generated[1].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fAUXx_vvpKS"
      },
      "source": [
        "## Parameters of previous model\n",
        "\n",
        "Its expected to be vocab_size * vocab_size total parameters since we just save pair wise params for our look table\n",
        "\n",
        "So its expected to be:  65 * 65 = 4225"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLqgQVKij5VS",
        "outputId": "e4cd8602-8355-4c85-ee05-05b890a9b55c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------------------+-------------------+\n",
            "|           Mod name           | Parameters Listed |\n",
            "+------------------------------+-------------------+\n",
            "| token_embedding_table.weight |        4225       |\n",
            "+------------------------------+-------------------+\n",
            "Sum of trained paramters: 4225\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "4225"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from prettytable import PrettyTable\n",
        "def count_parameters(model):\n",
        "  table = PrettyTable([\"Mod name\", \"Parameters Listed\"])\n",
        "  t_params = 0\n",
        "  for name, parameter in model.named_parameters():\n",
        "    if not parameter.requires_grad:\n",
        "      continue\n",
        "    param = parameter.numel()\n",
        "    table.add_row([name, param])\n",
        "    t_params+=param\n",
        "  print(table)\n",
        "  print(f\"Sum of trained paramters: {t_params}\")\n",
        "  return t_params\n",
        "count_parameters(m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeJYDFX9j5pe"
      },
      "source": [
        "## Create a PyTorch optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "eTyJ8qAaDdiF"
      },
      "outputs": [],
      "source": [
        "# torch.optim.AdamW is an optimization algorithm used for training neural networks. \n",
        "# It is a variant of the popular Adam optimization algorithm that includes an additional weight decay term, which helps to prevent overfitting.\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "Hs4kI8YdEkQj",
        "outputId": "c3348485-3af7-484b-f373-dc1ab6b60bda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 0, loss 4.648484230041504\n",
            "Step 1000, loss 3.7026753425598145\n",
            "Step 2000, loss 3.123114585876465\n",
            "Step 3000, loss 2.7292540073394775\n",
            "Step 4000, loss 2.570060968399048\n",
            "2.7019362449645996\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "batch_size = 32\n",
        "loss_history = []\n",
        "\n",
        "for steps in range(5000): # increase number of steps for good results... \n",
        "    \n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "\n",
        "    # The forward method of the BigramLanguageModel is called with the input minibatch xb \n",
        "    # and the corresponding target minibatch yb. \n",
        "    # The output of the forward method is a tuple of (logits, loss). \n",
        "    # logits contains the predicted output logits of the model, and loss contains the loss calculated between the predicted output and the target output\n",
        "    logits, loss = m(xb, yb)\n",
        "    # append loss history to plot\n",
        "    loss_history.append(loss.item())\n",
        "    # This line clears the gradients of all the parameters in the optimizer. \n",
        "    # This is necessary because gradients are accumulated by default during backpropagation, \n",
        "    # and if we don't clear them, they will keep increasing on subsequent iterations.\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    \n",
        "    # This line computes the gradients of the loss with respect to all the parameters of the model.\n",
        "    # This is done by traversing the computation graph in reverse order and \n",
        "    # applying the chain rule to compute the gradients.\n",
        "    loss.backward()\n",
        "    \n",
        "    # This line updates the parameters of the model using the gradients computed in the previous step.\n",
        "    optimizer.step()\n",
        "\n",
        "    # print loss every 1000 steps\n",
        "    if steps % 1000 == 0:\n",
        "        print(f'Step {steps}, loss {loss.item()}')\n",
        "\n",
        "print(loss.item())\n",
        "plt.plot(loss_history)\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7FqzwF12j3M"
      },
      "source": [
        "## Even if we trained for millions of steps, you shouldn't expect shakespeare coming out from such model :)\n",
        "\n",
        "Why? because its **Bigram** so generation of next token depends only on current token and no history !!\n",
        "\n",
        "However, It shows that it learns something indeed if you compare the generated text now from above! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcVIDWAZEtjN",
        "outputId": "1f0a56ee-3e1b-42bc-def9-dfe112287735"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Wawice my.\n",
            "\n",
            "Onstacomzoroup\n",
            "Yow&$FMOUf isth bot mil;KI!\n",
            "WARCKI iree sengmin lat Heriliov ts, anend n nghir.\n",
            "Swanousel lind me l.\n",
            "MAull ce hiry:\n",
            "Supr aisspllw y.\n",
            "Jurinke n Boopetelaves\n",
            "MP:\n",
            "\n",
            "Pl, d metSSkllo W-S:\n",
            "FourtCoiib3s the m dourivETENGShire s p-LOK:\n",
            "\n",
            "PxTre\n",
            "\n",
            "ALONomnterupt f s ar iris!\n",
            "m:\n",
            "\n",
            "Enge maleronth,\n",
            "MadPre?d my o myr f-NLIE!\n",
            "KENob&y, wardsal thisE:zLAnd uin cNI ayaraney Iry ts I&fr t c!\n",
            "MykenEETon, bemary.\n",
            "YoXy'WWh wne?m sora anghse.-e?nomangqqurien.\n",
            "Sand tho-ze cin s th llugivod, wimerc\n"
          ]
        }
      ],
      "source": [
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long, device=device), max_new_tokens=500)[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XinV8nmAnmKN"
      },
      "source": [
        "## The mathematical trick in self-attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tukiH-NbRBhA",
        "outputId": "9ccbf6a2-a765-4fb4-eb80-c8563745fe9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a=\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "--\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "--\n",
            "c=\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n"
          ]
        }
      ],
      "source": [
        "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3, 3))\n",
        "a = a / torch.sum(a, 1, keepdim=True)\n",
        "b = torch.randint(0,10,(3,2)).float()\n",
        "c = a @ b\n",
        "print('a=')\n",
        "print(a)\n",
        "print('--')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('--')\n",
        "print('c=')\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs_E24uRE8kr",
        "outputId": "b52109cb-0e90-4819-ede3-999e6a68b187"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# consider the following toy example:\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,2 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "86NuXX0fn7ps"
      },
      "outputs": [],
      "source": [
        "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "        xprev = x[b,:t+1] # (t,C)\n",
        "        xbow[b,t] = torch.mean(xprev, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhdOAd6-wXkZ",
        "outputId": "97315e7b-4f15-47d6-ca12-83fac23fba31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# version 2: using matrix multiply for a weighted aggregation\n",
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei = wei / wei.sum(1, keepdim=True)\n",
        "xbow2 = wei @ x # (T, T) @ (B, T, C) ----> (B, T, C)\n",
        "# so it will cast wei to (B, T, T)\n",
        "# so now : # (B, T, T) @ (B, T, C) ----> (B, T, C) where each of batch made in parallel\n",
        "torch.allclose(xbow, xbow2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOURrfG-ysoL",
        "outputId": "71fea0ba-8746-445c-facf-4a2484669ec1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# version 3: use Softmax\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "xbow3 = wei @ x\n",
        "torch.allclose(xbow, xbow3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDarxEWIRMKq",
        "outputId": "dca86a83-3156-43d9-d43e-d2034a9123fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# version 4: self-attention!\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,32 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "\n",
        "# let's see a single Head perform self-attention\n",
        "head_size = 16\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "k = key(x)   # (B, T, 16)\n",
        "q = query(x) # (B, T, 16)\n",
        "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
        "\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "#wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "v = value(x)\n",
        "out = wei @ v\n",
        "#out = wei @ x\n",
        "\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey3wKs02Kwz1"
      },
      "source": [
        "## Very important for previous Self Attention code\n",
        "Talking about a single batch only\n",
        "\n",
        "TxT matrix\n",
        "batch 1 : \n",
        "  \n",
        "\tq1k1 q1k2 .. q1kT\n",
        "            \n",
        "\tq2k1 q2k2 .. q2kT\n",
        "            \n",
        "\t..   ..   .. ..\n",
        "            \n",
        "\tqTk1 qTk2 .. qTkT\n",
        "\n",
        "\n",
        "values of batch 1 is T*16\n",
        "\n",
        "\tv11  v12  ... v1T\n",
        "\n",
        "\tv21  v22  ... v2T\n",
        "\n",
        "\t..   ..       ..\n",
        "\n",
        "\tvT1  vT2  ... vTT\n",
        "\n",
        "\n",
        "\n",
        "wei @ values = T*16 matrix = weighted values \n",
        "\n",
        "\tq1k1 v11 + q1k2 v21 + ...   q1k1 v12 + q1k2 v22 + ...\n",
        "\tq2k1 v11 + q2k2 v21 + ...   q2k1 v12 + q2k2 v22 + ...\n",
        "\n",
        "\n",
        "note: wei@values (one batch)\n",
        " \n",
        " row i : it's affected by query i only and this query has dot product with all keys then this dot product act as weights for each value\n",
        "\n",
        " col j : you make weighted average for along jth dimension only of all the values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT1hdtzXCjgL",
        "outputId": "b46f9130-348b-45e0-8438-e5137068d3ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
              "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
              "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wei[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5CvobiQ0pLr"
      },
      "source": [
        "Notes:\n",
        "- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
        "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
        "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
        "- In an \"encoder\" attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
        "- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
        "- \"Scaled\" attention additional divides `wei` by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I9qFDRZNHZ_"
      },
      "source": [
        "##Scaled attention and its use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kzl8urUPOHnw",
        "outputId": "d763e43f-2e80-449a-a274-801d83a544f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(17.4690)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# without using scaled attention\n",
        "# the problem is if you have unit gaussian inputs so zero mean unit variance K and Q are unit caution and if you just do\n",
        "# weight naively then you see that your weight's variance actually will be on the order of head size which in our\n",
        "# case is 16. \n",
        "k = torch.randn(B,T,head_size)\n",
        "q = torch.randn(B,T,head_size)\n",
        "wei = q @ k.transpose(-2, -1)\n",
        "k.var()\n",
        "q.var()\n",
        "wei.var()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpN48HbJOkAH"
      },
      "source": [
        "# So to overcome this \n",
        "If you multiply by one over head size square root so this is square root\n",
        "and this is one over then the variance of weight will be one so it will be preserved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4SNbLq5z3oBw"
      },
      "outputs": [],
      "source": [
        "k = torch.randn(B,T,head_size)\n",
        "q = torch.randn(B,T,head_size)\n",
        "wei = q @ k.transpose(-2, -1) * head_size**-0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl6I9n9IRTSo",
        "outputId": "62289df4-212f-4609-9240-b4472d1f7a66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.9006)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k.var()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1tQx7oeRvtc",
        "outputId": "592e17e1-3927-4bed-a395-29657ba15525"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.0037)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q.var()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLb_odHU3iKM",
        "outputId": "73c09ff7-3f9f-4fbb-a2c1-4870c3963aaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.9957)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wei.var()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRozqeQTPETe"
      },
      "source": [
        "# Why do we care about variance at all ? (Very Important !)\n",
        "\n",
        "you'll notice that way here will feed weight into softmax and so it's really important especially at initialization that way be fairly diffuse\n",
        "\n",
        "so in our case above here we sort of lucked out here and weight had a fairly diffuse numbers here so um like this now the problem is that because of softmax if weight takes on very positive and very negative numbers inside it softmax will actually converge towards one hot vectors\n",
        "\n",
        "we don't want these values to be too extreme especially the\n",
        "initialization otherwise softmax will be way too peaky and you're basically aggregating information from like a single node every node just aggregates information from a single other node that's not what\n",
        "we want "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB82yzt44REI",
        "outputId": "c866d567-c3f6-4782-c64f-08bf5c8aa762"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpt8569BB9_f",
        "outputId": "6b64b684-bc56-4e5a-d52a-7524942db3c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1) # gets too peaky, converges to one-hot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ0sAWd-PjY-"
      },
      "source": [
        "# Normalization "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Num7sX9CKOH",
        "outputId": "1ca3fd13-dd31-4fe2-dd86-600f956d8d5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 100])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class LayerNorm1d:\n",
        "  # normalizing the rows of the batch not the columns as batchNorm\n",
        "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "    self.eps = eps\n",
        "    self.gamma = torch.ones(dim)\n",
        "    self.beta = torch.zeros(dim)\n",
        "  \n",
        "  def __call__(self, x):\n",
        "    # calculate the forward pass\n",
        "    xmean = x.mean(1, keepdim=True) # batch mean\n",
        "    xvar = x.var(1, keepdim=True) # batch variance\n",
        "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
        "    self.out = self.gamma * xhat + self.beta\n",
        "    return self.out\n",
        "  \n",
        "  def parameters(self):\n",
        "    return [self.gamma, self.beta]\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "module = LayerNorm1d(100)\n",
        "x = torch.randn(32, 100) # batch size 32 of 100-dimensional vectors\n",
        "x = module(x)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "633T2cmnW1uk",
        "outputId": "5e595f0e-cb6b-42b4-d1e6-23bb00ebd0da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(0.1469), tensor(0.8803))"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[:,0].mean(), x[:,0].std() # mean,std of one feature across all batch inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN9cK9BoXCYb",
        "outputId": "a36347ea-4046-4bd2-a8d5-13e5f2c8893e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(-9.5367e-09), tensor(1.0000))"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[0,:].mean(), x[0,:].std() # mean,std of a single input from the batch, of its features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "dRJH6wM_XFfU"
      },
      "outputs": [],
      "source": [
        "# French to English translation example:\n",
        "\n",
        "# <--------- ENCODE ------------------><--------------- DECODE ----------------->\n",
        "# les réseaux de neurones sont géniaux! <START> neural networks are awesome!<END>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcvKeBXoZFOY"
      },
      "source": [
        "### Full finished code, for reference\n",
        "\n",
        "You may want to refer directly to the git repo instead though."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "M5p-N7uirzy-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoelkOrFY8bN",
        "outputId": "b955b613-8716-4123-9f50-6faba6f1c43d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.222593 M parameters\n",
            "step 0: train loss 4.2969, val loss 4.2924\n",
            "step 500: train loss 1.5916, val loss 1.7564\n",
            "step 1000: train loss 1.4001, val loss 1.6054\n",
            "step 1500: train loss 1.3235, val loss 1.5582\n",
            "step 2000: train loss 1.2739, val loss 1.5163\n",
            "step 2500: train loss 1.2402, val loss 1.5024\n",
            "step 3000: train loss 1.2128, val loss 1.4977\n",
            "step 3500: train loss 1.1920, val loss 1.4926\n",
            "step 4000: train loss 1.1713, val loss 1.4873\n",
            "step 4500: train loss 1.1540, val loss 1.4972\n",
            "step 4999: train loss 1.1367, val loss 1.4908\n",
            "\n",
            " HENRY VI:\n",
            "O Dorroh as science endirely hangs a hiselent,\n",
            "That you can inforcement\n",
            "That gentlewoman: women, I may long fear\n",
            "To answer writing your flowers; but the ground, tenders to say\n",
            "That I'll hear a devise with him, reser's:\n",
            "The morning of affair hath proffess'd your fond,\n",
            "Has hugg'd upon my moving father shall hear by,\n",
            "In peace out on mine and sign away;\n",
            "And bid that York; and the pitning of the\n",
            "body had been been side by that which full of it.\n",
            "\n",
            "GEORGE:\n",
            "Lords, are the weary? come I am in him there;\n",
            "Howly-a-dorn'd hap with the paint vollain?\n",
            "Madam, come, is not him, but yet on Rome to right\n",
            "Man: it is not power in him for bay,\n",
            "But in our daughter bear that, any thou cage on's hence.\n",
            "But Holy follows this bless,\n",
            "Yet the father againt, like a will pity,\n",
            "with, and I charit, in sin, that it were a rot\n",
            "fit by in a king, and famous yetnury shall an oyal,\n",
            "and employ aside of the Birthey, with thy brat,\n",
            "Nor I have had banished: his away! thyself will\n",
            "Throw aways to lose me a prettion on me.\n",
            "But, how not takest imagine: here will\n",
            "to preveen all your brothers againsaying tomberth\n",
            "And of my tradel, and still you healt:\n",
            "All believe pufful warm you Franches!\n",
            "That enclusing how the teach shift blood:\n",
            "And hulf to thy fancello! Leswiful lords?\n",
            "\n",
            "CLIFFORD:\n",
            "But thy 'adom, though God knake hand who courts\n",
            "For sits no natural banish'd, and in thee.\n",
            "\n",
            "NUS:\n",
            "Now, no fair with a natural than devil: Is't\n",
            "so aftred so six's, he'll let them well.\n",
            "\n",
            "COMINIUS:\n",
            "O mother!\n",
            "Ay, my good sir, on this gentleman, as therefore,\n",
            "With no hour broil: who should between's note\n",
            "That dreamerse cannot but wear that.\n",
            "\n",
            "First Servant:\n",
            "O Edward!\n",
            "\n",
            "PARIS:\n",
            "We have ended on that spend in Rome.\n",
            "\n",
            "MERCUTIO:\n",
            "\n",
            "Roman:\n",
            "Why spakest that of Lucio! times me that is took,\n",
            "That from twilvs: and then he like in \n",
            "a business conference then I would aufidius wide,\n",
            "The burxiging thee upon me away of men, dead.\n",
            "\n",
            "KING RICHARD II:\n",
            "Yet i' the fairer of his disgrace being calles.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "No head stringes brack'd in their looks\n",
            "H\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 128 # how many independent sequences will we process in parallel?\n",
        "block_size = 128 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 256\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.2\n",
        "# ------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "# @torch.no_grad() this line says to pytorch to prevent backprop since we will be evaluating not real training\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    # let model be in evaluation phase so layers like normalization, .. change their behaviour at inference time\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    # back to training phase\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.head_size = head_size\n",
        "        # I'm creating this Trill variable Trill is not a parameter of the module so in sort of pytorch\n",
        "        # conventions this is called a buffer it's not a parameter and you have to call it you have to assign it to the module\n",
        "        # using a register buffer so that creates the trail, the triangle lower triangular Matrix\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        # we can also drop out here when we calculate the basically affinities and after the softmax we can drop out\n",
        "        # some of those so we can randomly prevent some of the nodes from communicating\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * self.head_size**-0.5  # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        # a linear transformation layer that projects the concatenated output from the self.heads module to the original embedding size n_embd.\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        \n",
        "        # a dropout layer that randomly sets some of the output values to zero during training to prevent overfitting.\n",
        "        # Dropout is something that you can add right before the residual connection back or right before the connection back into the original pathway\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # we run all of the heads in parallel into a list and simply concatenate all of the outputs and we're concatenating over the channel dimension\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        # The module is defined using the PyTorch nn.Sequential class, which allows us to define a sequence of layers that are applied to the input in order.\n",
        "        # a feedforward neural network module with two linear layers, a ReLU activation function, and a dropout layer. \n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            # a dropout layer that randomly sets some of the output values to zero during training to prevent overfitting.\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        # n_head heads each of head_size-dimensional self attention running in parallel\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "\n",
        "        # feedforward neural network purpose: before when we had the multi-headed self-attention only that did the communication, we went way too fast\n",
        "        # to calculate the logits so the tokens looked at each other but didn't really have a lot of time to think on what they found from the other tokens\n",
        "        # notice: that the feed forward here when it's applying linear this is on a per token level all the tokens do this independently so the self-attention is the communication and \n",
        "        # then once they've gathered all the data now they need to think on that data individually and so that's what feed forward is doing\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "\n",
        "        # the size of the layer Norm here is n_embd of 32. so when the layer Norm is normalizing our features it is the normalization here\n",
        "        # happens the mean and the variance are taking over 32 numbers so the batch and the time act as batch Dimensions both of\n",
        "        # them so this is kind of like a per token transformation that just normalizes the features and makes them a unit mean unit gaussian at initialization\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # this is actually something that slightly departs from the original paper you see that the [ADD and Norm] is applied after the transformation\n",
        "        # but um in now it is a bit more basically common to apply the layer Norm before the transformation so there's a reshuffling of the layer Norms \n",
        "        # so this is called the [pre-norm formulation] and that's the one that we're going to implement as well\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "# super simple bigram model\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        # take care now embedding size (= n_embd) != vocab size \n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        # positional encoding lookup \n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        \n",
        "        # final layer norm at the end of the transfomer\n",
        "        self.ln_f = nn.LayerNorm(n_embd) \n",
        "        \n",
        "        # a fully connected (linear) layer by performing a linear transformation on the input tensor\n",
        "        # with a weight matrix of size (n_embd, vocab_size) and adding a bias vector of size (vocab_size,)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        \n",
        "        # now total embedding = token embedding + positional embedding\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        \n",
        "        # pass x into\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        # pass x into\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "\n",
        "        # logits is the ouput of the fully connected (linear) layer now given input x\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "\n",
        "            # because now we're using positional embeddings we can never have more than block size coming in because if idx is\n",
        "            # more than block size then our position embedding table is going to run out of scope because it only has embeddings for up to block size \n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
