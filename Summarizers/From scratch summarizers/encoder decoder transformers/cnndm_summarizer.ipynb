{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"fafa48adf760e89863c852971c7f6e563e041a06f543659c1b2ef78dcf8d05d3"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"0c98b1c6d1914acc8beb831d75f11ffe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_18beda8620f34e4292bd33075506cb2b","IPY_MODEL_1d305ef42a6e40129e24359c8aac1b87","IPY_MODEL_5df87049a43f4ecf9dff725b3bec1e7b"],"layout":"IPY_MODEL_8ad4ae8ded434f3680047726fae2c2e0"}},"18beda8620f34e4292bd33075506cb2b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01bdf40829144e9b9e27c5790ff0c744","placeholder":"​","style":"IPY_MODEL_396a47cc2d6e41b682702813934d8295","value":"Downloading builder script: 100%"}},"1d305ef42a6e40129e24359c8aac1b87":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ae665b7d17f45c984e2ab7fd802ae62","max":8326,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ce36865f468b4e669b6804d0e75f00d2","value":8326}},"5df87049a43f4ecf9dff725b3bec1e7b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08dfe32709fe4fefb0512df413d8f48b","placeholder":"​","style":"IPY_MODEL_20051e67af3c40dc83ac8fcc58a307d8","value":" 8.33k/8.33k [00:00&lt;00:00, 248kB/s]"}},"8ad4ae8ded434f3680047726fae2c2e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01bdf40829144e9b9e27c5790ff0c744":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"396a47cc2d6e41b682702813934d8295":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ae665b7d17f45c984e2ab7fd802ae62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce36865f468b4e669b6804d0e75f00d2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"08dfe32709fe4fefb0512df413d8f48b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20051e67af3c40dc83ac8fcc58a307d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b2db07828104b3da51d4d7208e621c3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a9b457c0f8a44383be9826bb9ca1bebc","IPY_MODEL_ab4b76bb16454e8d85ae4480a918f369","IPY_MODEL_e954c1f6e46e43a8bfedba836526a208"],"layout":"IPY_MODEL_41e44887d58946769b7f27698bd33370"}},"a9b457c0f8a44383be9826bb9ca1bebc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eaf76a937d074c9092932ad06bd7a0b4","placeholder":"​","style":"IPY_MODEL_9e681e64793845d2a68c0a7cf7fbfae7","value":"Downloading metadata: 100%"}},"ab4b76bb16454e8d85ae4480a918f369":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bcc2579f69b4d5dac859c2f4f1b4de2","max":9881,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d0e44e051ec40fdb8a86b1895f632bd","value":9881}},"e954c1f6e46e43a8bfedba836526a208":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d245b0ca9b184e2b96938ab6a2d17307","placeholder":"​","style":"IPY_MODEL_6ea13909856e457386a24c570c3cb812","value":" 9.88k/9.88k [00:00&lt;00:00, 247kB/s]"}},"41e44887d58946769b7f27698bd33370":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eaf76a937d074c9092932ad06bd7a0b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e681e64793845d2a68c0a7cf7fbfae7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9bcc2579f69b4d5dac859c2f4f1b4de2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d0e44e051ec40fdb8a86b1895f632bd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d245b0ca9b184e2b96938ab6a2d17307":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ea13909856e457386a24c570c3cb812":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe9395608a3a4468ba6058767d0636bf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_074ff8daed004f7890dd6cd39688e01b","IPY_MODEL_212a34452f0947189cc34b43adce35b1","IPY_MODEL_770bac5da5d1459fb2d5c85be8285e40"],"layout":"IPY_MODEL_d57bb90f16bd4dbf9d0ad27afb4a6caa"}},"074ff8daed004f7890dd6cd39688e01b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6359e6cfa6dc40b29b678f8a84e99012","placeholder":"​","style":"IPY_MODEL_500db5bef3ff4f3b85dd71b773be2a22","value":"Downloading readme: 100%"}},"212a34452f0947189cc34b43adce35b1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2660558092f8456782ac26b6ec8f6429","max":15079,"min":0,"orientation":"horizontal","style":"IPY_MODEL_be4093e4d408497b9482d6a398cd374c","value":15079}},"770bac5da5d1459fb2d5c85be8285e40":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0ce072bd5b94338bfa5ee75cb709943","placeholder":"​","style":"IPY_MODEL_a031b8e2521e4ed7bc52f5fb77e812d9","value":" 15.1k/15.1k [00:00&lt;00:00, 383kB/s]"}},"d57bb90f16bd4dbf9d0ad27afb4a6caa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6359e6cfa6dc40b29b678f8a84e99012":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"500db5bef3ff4f3b85dd71b773be2a22":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2660558092f8456782ac26b6ec8f6429":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be4093e4d408497b9482d6a398cd374c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f0ce072bd5b94338bfa5ee75cb709943":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a031b8e2521e4ed7bc52f5fb77e812d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99012d5c17414e519f2737468821a824":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_354719e9a06840d7ae82058fc2438659","IPY_MODEL_536b7f2cbbbc408f88e9216b31a6dcd7","IPY_MODEL_9c5b14150a66434b98e40cff6f47de62"],"layout":"IPY_MODEL_912cf788659449b0afd1de7718c0462b"}},"354719e9a06840d7ae82058fc2438659":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_318ed02edd5c4157b517c73e5f4c0ce7","placeholder":"​","style":"IPY_MODEL_f79bac0d86fe4a6c845f9539cd750006","value":"Downloading data files: 100%"}},"536b7f2cbbbc408f88e9216b31a6dcd7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_46ff13c043864a369439ab95b76bae86","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_75a444bafc1e4570918961d6a7399d7a","value":5}},"9c5b14150a66434b98e40cff6f47de62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_067a3801ba834177ba30199123b0f391","placeholder":"​","style":"IPY_MODEL_31de5b270e514d5cb8e041b24552eeff","value":" 5/5 [00:14&lt;00:00,  2.06s/it]"}},"912cf788659449b0afd1de7718c0462b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"318ed02edd5c4157b517c73e5f4c0ce7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f79bac0d86fe4a6c845f9539cd750006":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46ff13c043864a369439ab95b76bae86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75a444bafc1e4570918961d6a7399d7a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"067a3801ba834177ba30199123b0f391":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31de5b270e514d5cb8e041b24552eeff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56945b163fe941cbae999d8198e3d11e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3ec802122b114acdbffc24d9fbe7a402","IPY_MODEL_9c5bb05afbae4126b48b10de439ac3dc","IPY_MODEL_9c72d9be63194673bcf2003dc515f66d"],"layout":"IPY_MODEL_7c2f85b93f7f4e6d94de53e25d1d3262"}},"3ec802122b114acdbffc24d9fbe7a402":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24b47d6bebdf4022ade45d26b9326923","placeholder":"​","style":"IPY_MODEL_a5072fb9e2af4e98a2b0c9d7691cd314","value":"Downloading data: 100%"}},"9c5bb05afbae4126b48b10de439ac3dc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ad4ed0a05804295a55faa71cfb878ba","max":158577824,"min":0,"orientation":"horizontal","style":"IPY_MODEL_837f978675294614a1d09314548ad6ef","value":158577824}},"9c72d9be63194673bcf2003dc515f66d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2527949fbb04b57aac9fef9bcbcbcdc","placeholder":"​","style":"IPY_MODEL_0435bd61d87d41a386fb520045b9044a","value":" 159M/159M [00:03&lt;00:00, 57.0MB/s]"}},"7c2f85b93f7f4e6d94de53e25d1d3262":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24b47d6bebdf4022ade45d26b9326923":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5072fb9e2af4e98a2b0c9d7691cd314":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ad4ed0a05804295a55faa71cfb878ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"837f978675294614a1d09314548ad6ef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b2527949fbb04b57aac9fef9bcbcbcdc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0435bd61d87d41a386fb520045b9044a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12ad103040944a3285b480d52fae87db":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_be749a3907f54dea95771182fdd0fba3","IPY_MODEL_37f23f009d6a4e49b645b31d64f1465e","IPY_MODEL_da4deb219567416eb4d92c5af2d1d56d"],"layout":"IPY_MODEL_7eec52c4f6764238bcb902423f68fd6a"}},"be749a3907f54dea95771182fdd0fba3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_63a3dc4de7134e69afdaeaf6bb52b18a","placeholder":"​","style":"IPY_MODEL_2c43a8bbd50e482f83e7b7b85f5f1235","value":"Downloading data: 100%"}},"37f23f009d6a4e49b645b31d64f1465e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_61d08987dfce4bb2a21ca4f3cc645424","max":375893739,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d15726aeae3d4ad7970f3120d68923ae","value":375893739}},"da4deb219567416eb4d92c5af2d1d56d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03dd161c9e194448b604ea0862fcdbc3","placeholder":"​","style":"IPY_MODEL_4f7c04cb061343c49d516662d3ff7d5a","value":" 376M/376M [00:06&lt;00:00, 89.4MB/s]"}},"7eec52c4f6764238bcb902423f68fd6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63a3dc4de7134e69afdaeaf6bb52b18a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c43a8bbd50e482f83e7b7b85f5f1235":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61d08987dfce4bb2a21ca4f3cc645424":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d15726aeae3d4ad7970f3120d68923ae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"03dd161c9e194448b604ea0862fcdbc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f7c04cb061343c49d516662d3ff7d5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"605c7e7979d0410c85ee17e2ba4997f3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_437dc9802379450894700f3634adeae1","IPY_MODEL_2fda212ae1614a2380c17c81f04ce4a5","IPY_MODEL_1a68c0166f054cce9a7c8f7f8c2f25d9"],"layout":"IPY_MODEL_ea9fc46152094b1cb8985d6b6d7ebd11"}},"437dc9802379450894700f3634adeae1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64f214a602974bdf9cff26b94b9cbed2","placeholder":"​","style":"IPY_MODEL_8f2bcf78c13e4948b0e05a09e02e7b37","value":"Downloading data: "}},"2fda212ae1614a2380c17c81f04ce4a5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_31ac19f9c3314bb38850da27c2da5bae","max":12259516,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3cda2ac435d44d3cb14b60126c622ecc","value":12259516}},"1a68c0166f054cce9a7c8f7f8c2f25d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78785fbaa4e44620bb41581f7f9feeac","placeholder":"​","style":"IPY_MODEL_c275a783ce8249a98e8b6fe0438126f7","value":" 46.4M/? [00:00&lt;00:00, 59.9MB/s]"}},"ea9fc46152094b1cb8985d6b6d7ebd11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64f214a602974bdf9cff26b94b9cbed2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f2bcf78c13e4948b0e05a09e02e7b37":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31ac19f9c3314bb38850da27c2da5bae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cda2ac435d44d3cb14b60126c622ecc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78785fbaa4e44620bb41581f7f9feeac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c275a783ce8249a98e8b6fe0438126f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"718480e27fe44f8ead3787e0b79c5dfb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_85a4ebf126c444b4a5e1f312036e5f12","IPY_MODEL_63d6e9fa2f2240758c0024d3042e41ff","IPY_MODEL_a1b626169c6b446d8da4244b25989770"],"layout":"IPY_MODEL_a6488e8acea74df3a90c9c3fce687946"}},"85a4ebf126c444b4a5e1f312036e5f12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e48b23a44fc34416ba18b1600944e1f8","placeholder":"​","style":"IPY_MODEL_1712318142814158b77bfe14e1de0327","value":"Downloading data: "}},"63d6e9fa2f2240758c0024d3042e41ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c20bed9e18d414bb31702541c673d6a","max":660943,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a89fc3c597d04ff8befe7600c3b34f78","value":660943}},"a1b626169c6b446d8da4244b25989770":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_854b4b5b22554c3ba6657254a54d346c","placeholder":"​","style":"IPY_MODEL_4ce48ebaafb64aa4ae63b8486899ab4f","value":" 2.43M/? [00:00&lt;00:00, 34.4MB/s]"}},"a6488e8acea74df3a90c9c3fce687946":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e48b23a44fc34416ba18b1600944e1f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1712318142814158b77bfe14e1de0327":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c20bed9e18d414bb31702541c673d6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a89fc3c597d04ff8befe7600c3b34f78":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"854b4b5b22554c3ba6657254a54d346c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ce48ebaafb64aa4ae63b8486899ab4f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e367018ec174826be5a393f79512d77":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ebb61664f3a421b95bc810769286434","IPY_MODEL_a312095be57f4d39ae5abaf760a786da","IPY_MODEL_449903b011b54d4ab17365368e1ebb70"],"layout":"IPY_MODEL_2f373066f29c402499c07bbac69aa69b"}},"9ebb61664f3a421b95bc810769286434":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55d21d954b814c58af572baad5045dd2","placeholder":"​","style":"IPY_MODEL_64dbac93d852427b802ed175f0875ef5","value":"Downloading data: "}},"a312095be57f4d39ae5abaf760a786da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8079c5b3e6f4416e9c5439727bc27420","max":572061,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ceef13ceabf847b68cb70b57c10dd24c","value":572061}},"449903b011b54d4ab17365368e1ebb70":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00bcc669c86a406aa71cef2b15af6ec1","placeholder":"​","style":"IPY_MODEL_7abbf0cee5b84a16a24aca215d4529f5","value":" 2.11M/? [00:00&lt;00:00, 30.7MB/s]"}},"2f373066f29c402499c07bbac69aa69b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55d21d954b814c58af572baad5045dd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64dbac93d852427b802ed175f0875ef5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8079c5b3e6f4416e9c5439727bc27420":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ceef13ceabf847b68cb70b57c10dd24c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"00bcc669c86a406aa71cef2b15af6ec1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7abbf0cee5b84a16a24aca215d4529f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc6a9a5c42014b8a934fbbb8bcdfbcbd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5a89b3b5f56e4c8285954316672b6a04","IPY_MODEL_5834280afb824017864709100e454c2e","IPY_MODEL_8a4e8fff3b774a5a92e28d43096ba2f9"],"layout":"IPY_MODEL_ddc183e4f9a74aceaec116336b4c2a84"}},"5a89b3b5f56e4c8285954316672b6a04":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d7e46af7589491d8ddbed7574c6c035","placeholder":"​","style":"IPY_MODEL_6f7a53677f614a67bb61c569a59e2f92","value":"Generating train split: 100%"}},"5834280afb824017864709100e454c2e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c267ffabf33424686d25d16c04e14fa","max":287113,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7e71fbff37ac46ffad8d9bc23a745708","value":287113}},"8a4e8fff3b774a5a92e28d43096ba2f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ca0e8885aa44d49a7459b49629af164","placeholder":"​","style":"IPY_MODEL_53a504503d86443c963e89410136accf","value":" 287113/287113 [01:39&lt;00:00, 293.43 examples/s]"}},"ddc183e4f9a74aceaec116336b4c2a84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"4d7e46af7589491d8ddbed7574c6c035":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f7a53677f614a67bb61c569a59e2f92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c267ffabf33424686d25d16c04e14fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e71fbff37ac46ffad8d9bc23a745708":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6ca0e8885aa44d49a7459b49629af164":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53a504503d86443c963e89410136accf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5d9805ea7c541098aeea00f48a530f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6d906adc70b6498abb8212bb6ab42e45","IPY_MODEL_33ab20f3130f404093d386830f7243bf","IPY_MODEL_faa17e97b90b4eb2bac290d53981173d"],"layout":"IPY_MODEL_0f186e3a0ca54df1aaaee9c1b09cc281"}},"6d906adc70b6498abb8212bb6ab42e45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21bf046f01fc413d9b73540e88e6472a","placeholder":"​","style":"IPY_MODEL_9441a1810a524d2b96fd925643e676e4","value":"Generating validation split: 100%"}},"33ab20f3130f404093d386830f7243bf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c25c3d6a2c754644aea4b3184ac21709","max":13368,"min":0,"orientation":"horizontal","style":"IPY_MODEL_83b5122b2cb047199c746e825075b7bf","value":13368}},"faa17e97b90b4eb2bac290d53981173d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56ef967c7e6542a3a94c851793cce160","placeholder":"​","style":"IPY_MODEL_2079d2f3f0204c7c8b7f0e60b8eb5b0c","value":" 13368/13368 [00:41&lt;00:00, 478.99 examples/s]"}},"0f186e3a0ca54df1aaaee9c1b09cc281":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"21bf046f01fc413d9b73540e88e6472a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9441a1810a524d2b96fd925643e676e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c25c3d6a2c754644aea4b3184ac21709":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83b5122b2cb047199c746e825075b7bf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"56ef967c7e6542a3a94c851793cce160":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2079d2f3f0204c7c8b7f0e60b8eb5b0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3dce6c3d1ec48c6adedcfe46a39ae26":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_40f811fd903f4e0d9341d68a15c5428b","IPY_MODEL_85427054a5954892bc4aedec8d4a53a6","IPY_MODEL_33103da6ce0443a7873dcbd5278e203c"],"layout":"IPY_MODEL_ad0a05522fec47e39dbecd829005ce6d"}},"40f811fd903f4e0d9341d68a15c5428b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbaa6ab22b174e36bd1f11c2e4bc3d83","placeholder":"​","style":"IPY_MODEL_8101326749f2405da7387dc1965b7d9e","value":"Generating test split: 100%"}},"85427054a5954892bc4aedec8d4a53a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_78b02e54787c479a9648fb2ac49177db","max":11490,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f6bc91e041ae4724bf58031722f836b0","value":11490}},"33103da6ce0443a7873dcbd5278e203c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a7fbe731fc4493cb6c7338051fec015","placeholder":"​","style":"IPY_MODEL_21f6861e81824c168d2b1445010ee1d7","value":" 11490/11490 [00:40&lt;00:00, 2130.88 examples/s]"}},"ad0a05522fec47e39dbecd829005ce6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"cbaa6ab22b174e36bd1f11c2e4bc3d83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8101326749f2405da7387dc1965b7d9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"78b02e54787c479a9648fb2ac49177db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6bc91e041ae4724bf58031722f836b0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a7fbe731fc4493cb6c7338051fec015":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21f6861e81824c168d2b1445010ee1d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b5ad6aba33d54c33a5cb6b86097ce915":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_df1550bf22a747009f42ed72f1d42abf","IPY_MODEL_5758d328ef5d42c788deacf31d50e3a8","IPY_MODEL_d0debc9ae3794b3c9393a74e002a1253"],"layout":"IPY_MODEL_7dcc8f24c9a14126a1344bdef8a459d5"}},"df1550bf22a747009f42ed72f1d42abf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c410cf2e72d4d3da221b073fb553c5e","placeholder":"​","style":"IPY_MODEL_79c489c8180e4d9ca35ff85c856bd13e","value":"100%"}},"5758d328ef5d42c788deacf31d50e3a8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a81d01603e754ebcb0bf63a0c5795a7a","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2cccc64cfaf6411488f4e10c55acd07e","value":3}},"d0debc9ae3794b3c9393a74e002a1253":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4f5304217924ae6911cb5ccb728a834","placeholder":"​","style":"IPY_MODEL_8976e9ec28264587a3db32dd600e0411","value":" 3/3 [00:00&lt;00:00, 70.35it/s]"}},"7dcc8f24c9a14126a1344bdef8a459d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c410cf2e72d4d3da221b073fb553c5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79c489c8180e4d9ca35ff85c856bd13e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a81d01603e754ebcb0bf63a0c5795a7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cccc64cfaf6411488f4e10c55acd07e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b4f5304217924ae6911cb5ccb728a834":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8976e9ec28264587a3db32dd600e0411":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This is a encoder decode Transformer used for abstractive Summarization\n## It uses subword tokenization pretrained by bert-base-cased\n## Moreover, It relies on the articles of CNN DailyMail Dataset\n## It's trained using A P100 GPU for 10000 batches\n## All hyperparameters are down ","metadata":{"id":"c_1a63xBlswK"}},{"cell_type":"code","source":"import numpy as np\nfrom numpy import array\nfrom numpy import asarray\nfrom numpy import zeros\nimport torch\nfrom transformers import AutoTokenizer\nimport pandas as pd\nimport tensorflow as tf\nimport time\nimport re\nimport pickle\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport random\nfrom datasets import load_dataset","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zbxhyl_zFlWL","outputId":"d2c450a8-abc6-49fc-f10d-62dfd06c06dc","execution":{"iopub.status.busy":"2023-05-05T18:11:18.189127Z","iopub.execute_input":"2023-05-05T18:11:18.189771Z","iopub.status.idle":"2023-05-05T18:11:28.462120Z","shell.execute_reply.started":"2023-05-05T18:11:18.189738Z","shell.execute_reply":"2023-05-05T18:11:28.461069Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KJJIJFeblswU","outputId":"42dca388-ce4c-4c01-922e-7e862d361773","execution":{"iopub.status.busy":"2023-05-05T18:11:28.464208Z","iopub.execute_input":"2023-05-05T18:11:28.464876Z","iopub.status.idle":"2023-05-05T18:11:28.496406Z","shell.execute_reply.started":"2023-05-05T18:11:28.464844Z","shell.execute_reply":"2023-05-05T18:11:28.494678Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Loading Data","metadata":{"id":"yH5cg5pSIHaZ"}},{"cell_type":"code","source":"# load the CNN/DailyMail dataset\ndataset = load_dataset('cnn_dailymail', '3.0.0')\n\n# print the first example\nprint(dataset['train'][0])\n","metadata":{"id":"K_AjGkWXITKA","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["0c98b1c6d1914acc8beb831d75f11ffe","18beda8620f34e4292bd33075506cb2b","1d305ef42a6e40129e24359c8aac1b87","5df87049a43f4ecf9dff725b3bec1e7b","8ad4ae8ded434f3680047726fae2c2e0","01bdf40829144e9b9e27c5790ff0c744","396a47cc2d6e41b682702813934d8295","9ae665b7d17f45c984e2ab7fd802ae62","ce36865f468b4e669b6804d0e75f00d2","08dfe32709fe4fefb0512df413d8f48b","20051e67af3c40dc83ac8fcc58a307d8","2b2db07828104b3da51d4d7208e621c3","a9b457c0f8a44383be9826bb9ca1bebc","ab4b76bb16454e8d85ae4480a918f369","e954c1f6e46e43a8bfedba836526a208","41e44887d58946769b7f27698bd33370","eaf76a937d074c9092932ad06bd7a0b4","9e681e64793845d2a68c0a7cf7fbfae7","9bcc2579f69b4d5dac859c2f4f1b4de2","0d0e44e051ec40fdb8a86b1895f632bd","d245b0ca9b184e2b96938ab6a2d17307","6ea13909856e457386a24c570c3cb812","fe9395608a3a4468ba6058767d0636bf","074ff8daed004f7890dd6cd39688e01b","212a34452f0947189cc34b43adce35b1","770bac5da5d1459fb2d5c85be8285e40","d57bb90f16bd4dbf9d0ad27afb4a6caa","6359e6cfa6dc40b29b678f8a84e99012","500db5bef3ff4f3b85dd71b773be2a22","2660558092f8456782ac26b6ec8f6429","be4093e4d408497b9482d6a398cd374c","f0ce072bd5b94338bfa5ee75cb709943","a031b8e2521e4ed7bc52f5fb77e812d9","99012d5c17414e519f2737468821a824","354719e9a06840d7ae82058fc2438659","536b7f2cbbbc408f88e9216b31a6dcd7","9c5b14150a66434b98e40cff6f47de62","912cf788659449b0afd1de7718c0462b","318ed02edd5c4157b517c73e5f4c0ce7","f79bac0d86fe4a6c845f9539cd750006","46ff13c043864a369439ab95b76bae86","75a444bafc1e4570918961d6a7399d7a","067a3801ba834177ba30199123b0f391","31de5b270e514d5cb8e041b24552eeff","56945b163fe941cbae999d8198e3d11e","3ec802122b114acdbffc24d9fbe7a402","9c5bb05afbae4126b48b10de439ac3dc","9c72d9be63194673bcf2003dc515f66d","7c2f85b93f7f4e6d94de53e25d1d3262","24b47d6bebdf4022ade45d26b9326923","a5072fb9e2af4e98a2b0c9d7691cd314","0ad4ed0a05804295a55faa71cfb878ba","837f978675294614a1d09314548ad6ef","b2527949fbb04b57aac9fef9bcbcbcdc","0435bd61d87d41a386fb520045b9044a","12ad103040944a3285b480d52fae87db","be749a3907f54dea95771182fdd0fba3","37f23f009d6a4e49b645b31d64f1465e","da4deb219567416eb4d92c5af2d1d56d","7eec52c4f6764238bcb902423f68fd6a","63a3dc4de7134e69afdaeaf6bb52b18a","2c43a8bbd50e482f83e7b7b85f5f1235","61d08987dfce4bb2a21ca4f3cc645424","d15726aeae3d4ad7970f3120d68923ae","03dd161c9e194448b604ea0862fcdbc3","4f7c04cb061343c49d516662d3ff7d5a","605c7e7979d0410c85ee17e2ba4997f3","437dc9802379450894700f3634adeae1","2fda212ae1614a2380c17c81f04ce4a5","1a68c0166f054cce9a7c8f7f8c2f25d9","ea9fc46152094b1cb8985d6b6d7ebd11","64f214a602974bdf9cff26b94b9cbed2","8f2bcf78c13e4948b0e05a09e02e7b37","31ac19f9c3314bb38850da27c2da5bae","3cda2ac435d44d3cb14b60126c622ecc","78785fbaa4e44620bb41581f7f9feeac","c275a783ce8249a98e8b6fe0438126f7","718480e27fe44f8ead3787e0b79c5dfb","85a4ebf126c444b4a5e1f312036e5f12","63d6e9fa2f2240758c0024d3042e41ff","a1b626169c6b446d8da4244b25989770","a6488e8acea74df3a90c9c3fce687946","e48b23a44fc34416ba18b1600944e1f8","1712318142814158b77bfe14e1de0327","7c20bed9e18d414bb31702541c673d6a","a89fc3c597d04ff8befe7600c3b34f78","854b4b5b22554c3ba6657254a54d346c","4ce48ebaafb64aa4ae63b8486899ab4f","2e367018ec174826be5a393f79512d77","9ebb61664f3a421b95bc810769286434","a312095be57f4d39ae5abaf760a786da","449903b011b54d4ab17365368e1ebb70","2f373066f29c402499c07bbac69aa69b","55d21d954b814c58af572baad5045dd2","64dbac93d852427b802ed175f0875ef5","8079c5b3e6f4416e9c5439727bc27420","ceef13ceabf847b68cb70b57c10dd24c","00bcc669c86a406aa71cef2b15af6ec1","7abbf0cee5b84a16a24aca215d4529f5","cc6a9a5c42014b8a934fbbb8bcdfbcbd","5a89b3b5f56e4c8285954316672b6a04","5834280afb824017864709100e454c2e","8a4e8fff3b774a5a92e28d43096ba2f9","ddc183e4f9a74aceaec116336b4c2a84","4d7e46af7589491d8ddbed7574c6c035","6f7a53677f614a67bb61c569a59e2f92","3c267ffabf33424686d25d16c04e14fa","7e71fbff37ac46ffad8d9bc23a745708","6ca0e8885aa44d49a7459b49629af164","53a504503d86443c963e89410136accf","a5d9805ea7c541098aeea00f48a530f2","6d906adc70b6498abb8212bb6ab42e45","33ab20f3130f404093d386830f7243bf","faa17e97b90b4eb2bac290d53981173d","0f186e3a0ca54df1aaaee9c1b09cc281","21bf046f01fc413d9b73540e88e6472a","9441a1810a524d2b96fd925643e676e4","c25c3d6a2c754644aea4b3184ac21709","83b5122b2cb047199c746e825075b7bf","56ef967c7e6542a3a94c851793cce160","2079d2f3f0204c7c8b7f0e60b8eb5b0c","a3dce6c3d1ec48c6adedcfe46a39ae26","40f811fd903f4e0d9341d68a15c5428b","85427054a5954892bc4aedec8d4a53a6","33103da6ce0443a7873dcbd5278e203c","ad0a05522fec47e39dbecd829005ce6d","cbaa6ab22b174e36bd1f11c2e4bc3d83","8101326749f2405da7387dc1965b7d9e","78b02e54787c479a9648fb2ac49177db","f6bc91e041ae4724bf58031722f836b0","2a7fbe731fc4493cb6c7338051fec015","21f6861e81824c168d2b1445010ee1d7","b5ad6aba33d54c33a5cb6b86097ce915","df1550bf22a747009f42ed72f1d42abf","5758d328ef5d42c788deacf31d50e3a8","d0debc9ae3794b3c9393a74e002a1253","7dcc8f24c9a14126a1344bdef8a459d5","6c410cf2e72d4d3da221b073fb553c5e","79c489c8180e4d9ca35ff85c856bd13e","a81d01603e754ebcb0bf63a0c5795a7a","2cccc64cfaf6411488f4e10c55acd07e","b4f5304217924ae6911cb5ccb728a834","8976e9ec28264587a3db32dd600e0411"]},"outputId":"51c03bc3-1416-41f7-ac47-0739574ab09f","execution":{"iopub.status.busy":"2023-05-05T18:11:28.498111Z","iopub.execute_input":"2023-05-05T18:11:28.498676Z","iopub.status.idle":"2023-05-05T18:15:07.351523Z","shell.execute_reply.started":"2023-05-05T18:11:28.498644Z","shell.execute_reply":"2023-05-05T18:15:07.349639Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/3.51k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7abfd5c35444a77ae3e19b0fcf04195"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.61k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1df0c614bbc947ed8a7e3a3d15e926c9"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset cnn_dailymail/3.0.0 (download: 558.32 MiB, generated: 1.28 GiB, post-processed: Unknown size, total: 1.82 GiB) to /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"017028df935e4f299db34a794f1b6815"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/159M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"979835084b814a3f9c09e991d964f73f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/376M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d384d8bd92143ca8a6c19c49cc2487d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/572k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e56b48f4f4e42db9fe68a58bc3a5791"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/12.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30495b94fde04e208400d5188e8ece02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/661k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da787127e3e34c1399c2d6c490caf441"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be4e4b1c71084afe94527f4c6612b68e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset cnn_dailymail downloaded and prepared to /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"378354472a95434181606a93de4243bf"}},"metadata":{}},{"name":"stdout","text":"{'article': 'It\\'s official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force \"to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction.\" It\\'s a step that is set to turn an international crisis into a fierce domestic political battle. There are key questions looming over the debate: What did U.N. weapons inspectors find in Syria? What happens if Congress votes no? And how will the Syrian government react? In a televised address from the White House Rose Garden earlier Saturday, the president said he would take his case to Congress, not because he has to -- but because he wants to. \"While I believe I have the authority to carry out this military action without specific congressional authorization, I know that the country will be stronger if we take this course, and our actions will be even more effective,\" he said. \"We should have this debate, because the issues are too big for business as usual.\" Obama said top congressional leaders had agreed to schedule a debate when the body returns to Washington on September 9. The Senate Foreign Relations Committee will hold a hearing over the matter on Tuesday, Sen. Robert Menendez said. Transcript: Read Obama\\'s full remarks . Syrian crisis: Latest developments . U.N. inspectors leave Syria . Obama\\'s remarks came shortly after U.N. inspectors left Syria, carrying evidence that will determine whether chemical weapons were used in an attack early last week in a Damascus suburb. \"The aim of the game here, the mandate, is very clear -- and that is to ascertain whether chemical weapons were used -- and not by whom,\" U.N. spokesman Martin Nesirky told reporters on Saturday. But who used the weapons in the reported toxic gas attack in a Damascus suburb on August 21 has been a key point of global debate over the Syrian crisis. Top U.S. officials have said there\\'s no doubt that the Syrian government was behind it, while Syrian officials have denied responsibility and blamed jihadists fighting with the rebels. British and U.S. intelligence reports say the attack involved chemical weapons, but U.N. officials have stressed the importance of waiting for an official report from inspectors. The inspectors will share their findings with U.N. Secretary-General Ban Ki-moon Ban, who has said he wants to wait until the U.N. team\\'s final report is completed before presenting it to the U.N. Security Council. The Organization for the Prohibition of Chemical Weapons, which nine of the inspectors belong to, said Saturday that it could take up to three weeks to analyze the evidence they collected. \"It needs time to be able to analyze the information and the samples,\" Nesirky said. He noted that Ban has repeatedly said there is no alternative to a political solution to the crisis in Syria, and that \"a military solution is not an option.\" Bergen:  Syria is a problem from hell for the U.S. Obama: \\'This menace must be confronted\\' Obama\\'s senior advisers have debated the next steps to take, and the president\\'s comments Saturday came amid mounting political pressure over the situation in Syria. Some U.S. lawmakers have called for immediate action while others warn of stepping into what could become a quagmire. Some global leaders have expressed support, but the British Parliament\\'s vote against military action earlier this week was a blow to Obama\\'s hopes of getting strong backing from key NATO allies. On Saturday, Obama proposed what he said would be a limited military action against Syrian President Bashar al-Assad. Any military attack would not be open-ended or include U.S. ground forces, he said. Syria\\'s alleged use of chemical weapons earlier this month \"is an assault on human dignity,\" the president said. A failure to respond with force, Obama argued,  \"could lead to escalating use of chemical weapons or their proliferation to terrorist groups who would do our people harm. In a world with many dangers, this menace must be confronted.\" Syria missile strike: What would happen next? Map: U.S. and allied assets around Syria . Obama decision came Friday night . On Friday night, the president made a last-minute decision to consult lawmakers. What will happen if they vote no? It\\'s unclear. A senior administration official told CNN that Obama has the authority to act without Congress -- even if Congress rejects his request for authorization to use force. Obama on Saturday continued to shore up support for a strike on the al-Assad government. He spoke by phone with French President Francois Hollande before his Rose Garden speech. \"The two leaders agreed that the international community must deliver a resolute message to the Assad regime -- and others who would consider using chemical weapons -- that these crimes are unacceptable and those who violate this international norm will be held accountable by the world,\" the White House said. Meanwhile, as uncertainty loomed over how Congress would weigh in, U.S. military officials said they remained at the ready. 5 key assertions: U.S. intelligence report on Syria . Syria: Who wants what after chemical weapons horror . Reactions mixed to Obama\\'s speech . A spokesman for the Syrian National Coalition said that the opposition group was disappointed by Obama\\'s announcement. \"Our fear now is that the lack of action could embolden the regime and they repeat his attacks in a more serious way,\" said spokesman Louay Safi. \"So we are quite concerned.\" Some members of Congress applauded Obama\\'s decision. House Speaker John Boehner, Majority Leader Eric Cantor, Majority Whip Kevin McCarthy and Conference Chair Cathy McMorris Rodgers issued a statement Saturday praising the president. \"Under the Constitution, the responsibility to declare war lies with Congress,\" the Republican lawmakers said. \"We are glad the president is seeking authorization for any military action in Syria in response to serious, substantive questions being raised.\" More than 160 legislators, including 63 of Obama\\'s fellow Democrats, had signed letters calling for either a vote or at least a \"full debate\" before any U.S. action. British Prime Minister David Cameron, whose own attempt to get lawmakers in his country to support military action in Syria failed earlier this week, responded to Obama\\'s speech in a Twitter post Saturday. \"I understand and support Barack Obama\\'s position on Syria,\" Cameron said. An influential lawmaker in Russia -- which has stood by Syria and criticized the United States -- had his own theory. \"The main reason Obama is turning to the Congress:  the military operation did not get enough support either in the world, among allies of the US or in the United States itself,\" Alexei Pushkov, chairman of the international-affairs committee of the Russian State Duma, said in a Twitter post. In the United States, scattered groups of anti-war protesters around the country took to the streets Saturday. \"Like many other Americans...we\\'re just tired of the United States getting involved and invading and bombing other countries,\" said Robin Rosecrans, who was among hundreds at a Los Angeles demonstration. What do Syria\\'s neighbors think? Why Russia, China, Iran stand by Assad . Syria\\'s government unfazed . After Obama\\'s speech, a military and political analyst on Syrian state TV said Obama is \"embarrassed\" that Russia opposes military action against Syria, is \"crying for help\" for someone to come to his rescue and is facing two defeats -- on the political and military levels. Syria\\'s prime minister appeared unfazed by the saber-rattling. \"The Syrian Army\\'s status is on maximum readiness and fingers are on the trigger to confront all challenges,\" Wael Nader al-Halqi said during a meeting with a delegation of Syrian expatriates from Italy, according to a banner on Syria State TV that was broadcast prior to Obama\\'s address. An anchor on Syrian state television said Obama \"appeared to be preparing for an aggression on Syria based on repeated lies.\" A top Syrian diplomat told the state television network that Obama was facing pressure to take military action from Israel, Turkey, some Arabs and right-wing extremists in the United States. \"I think he has done well by doing what Cameron did in terms of taking the issue to Parliament,\" said Bashar Jaafari, Syria\\'s ambassador to the United Nations. Both Obama and Cameron, he said, \"climbed to the top of the tree and don\\'t know how to get down.\" The Syrian government has denied that it used chemical weapons in the August 21 attack, saying that jihadists fighting with the rebels used them in an effort to turn global sentiments against it. British intelligence had put the number of people killed in the attack at more than 350. On Saturday, Obama said \"all told, well over 1,000 people were murdered.\" U.S. Secretary of State John Kerry on Friday cited a death toll of 1,429, more than 400 of them children. No explanation was offered for the discrepancy. Iran: U.S. military action in Syria would spark \\'disaster\\' Opinion: Why strikes in Syria are a bad idea .', 'highlights': 'Syrian official: Obama climbed to the top of the tree, \"doesn\\'t know how to get down\"\\nObama sends a letter to the heads of the House and Senate .\\nObama to seek congressional approval on military action against Syria .\\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .', 'id': '0001d1afc246a7964130f43ae940af6bc6c57f01'}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## converting dataset to pandas","metadata":{"id":"7mMpLMhtjuSd"}},{"cell_type":"code","source":"train = pd.DataFrame(dataset['train'])\ndocument = train['article']\nsummary = train['highlights']\n","metadata":{"id":"S-rYZhayIe9x","execution":{"iopub.status.busy":"2023-05-05T18:15:07.354046Z","iopub.execute_input":"2023-05-05T18:15:07.354989Z","iopub.status.idle":"2023-05-05T18:15:25.366795Z","shell.execute_reply.started":"2023-05-05T18:15:07.354953Z","shell.execute_reply":"2023-05-05T18:15:25.365829Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"document[30], summary[30]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2z55AhpKIdK7","outputId":"0c076cac-8c52-41f6-ba97-6f633297eed2","execution":{"iopub.status.busy":"2023-05-05T18:15:25.368090Z","iopub.execute_input":"2023-05-05T18:15:25.368457Z","iopub.status.idle":"2023-05-05T18:15:25.377425Z","shell.execute_reply.started":"2023-05-05T18:15:25.368406Z","shell.execute_reply":"2023-05-05T18:15:25.376328Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"('(CNN) -- The big winners of this Formula One season could be road drivers rather than F1 racers, according to one former world champion. Jody Scheckter, who took the drivers\\' title in 1979, hopes a raft of technological changes -- notably smaller, hybrid engines that promise greater fuel efficiency -- will help improve road cars\\' performance. \"It\\'s very positive for the sport, this is the first time you\\'ve seen the sport bring in regulations that really push the envelope of technology for every type of car,\" the South African told CNN. \"They are trying to take efficiency from everywhere they can on a car.\" This year\\'s race cars will boast an enhanced Energy Recovery System (ERS) and 1.6-liter V6 engines, compared to the 2.4-liter V8s on show last year. The ERS uses heat generated when braking and thermal energy from exhaust gases to create extra power. The Kinetic Energy Recovery System (KERS) has been used in F1 since 2009, but Scheckter says these latest advancements in the sport will only benefit everyday drivers. \"Wherever there is heat, they turn that into energy,\" added the former Ferrari driver. \"From that point of view, that\\'s what road cars are becoming more and more. \"They\\'ve taken this energy from the brakes and these different areas, that\\'s what Formula One has done to a much higher degree than I\\'ve ever seen before. I think the technology will flow to road cars very quickly. \"It\\'s very important for the global environment that they can make the technology work practically and then it can move into road cars.\" On the track, Scheckter expects an unpredictable start to the championship as teams and drivers wrestle with the new regulations. An encouraging preseason for Mercedes has fueled talk that Lewis Hamilton is the favorite for this weekend\\'s Australian Grand Prix and in pole position to take the title. Hamilton, a world champion in 2008, set the fastest time on the final day of the final test event in Bahrain, but the quickest lap time of preseason was set by Felipe Massa of Williams. The Brazilian is a new arrival at the British team following nine years with Ferrari and Scheckter expects Massa and Hamilton to start well, but he stopped short of tipping either to be top of the pile at the end of the season. \"If you\\'re going to follow some of the test results then you have to think that Mercedes and Williams have got an advantage at the beginning,\" he said. \"How long it will take for other teams to catch up, who knows? \"I would\\'ve thought after the fourth, fifth race, you might see things settle down. Someone could make a modification and gain one second, two seconds per lap. That is a massive amount. So until things settle down I wouldn\\'t want to back anybody.\" The climax of the 2014 season is set to be a dramatic one, with double points set to be awarded to the driver who takes the checkered flag at November\\'s Abu Dhabi Grand Prix, with the winner of that race awarded 50 points, rather than the usual 25. It\\'s a move that Scheckter thinks will see the fight for the world championship go down to the wire. \"What they are trying to do is make it so the last race determines the championship,\" he said. \"If somebody is quite far ahead and it looks like he\\'s going to win the championship ... if he doesn\\'t finish and another guy does he wins. \"Is that fair? No it\\'s not, but it makes exciting racing. Or it makes you throw something at the TV!\" Interactive: 10 cars that changed Formula One .',\n \"The first race of the 2014 Formula One season takes place in Australia on Sunday .\\nTurbo engines are back in the sport, with each car boasting a 1.6-liter V6 hybrid .\\nFormer F1 winner Jody Scheckter expects F1 technology to trickle down to road cars .\\nFor the first time in the sport's history, double points will be awarded at the year's final race .\")"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Obtaining insights on lengths for defining maxlen","metadata":{"id":"mZden_q9_eZr"}},{"cell_type":"code","source":"document = document[:100000]\nsummary = summary[:100000]","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:15:25.379163Z","iopub.execute_input":"2023-05-05T18:15:25.379856Z","iopub.status.idle":"2023-05-05T18:15:25.384398Z","shell.execute_reply.started":"2023-05-05T18:15:25.379825Z","shell.execute_reply":"2023-05-05T18:15:25.383603Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# words count in each \ndocument_lengths = pd.Series([len(x.split()) for x in document])\nsummary_lengths = pd.Series([len(x.split()) for x in summary])","metadata":{"id":"ma4o2nGdK5Xb","execution":{"iopub.status.busy":"2023-05-05T18:15:25.385756Z","iopub.execute_input":"2023-05-05T18:15:25.386073Z","iopub.status.idle":"2023-05-05T18:15:28.576798Z","shell.execute_reply.started":"2023-05-05T18:15:25.386044Z","shell.execute_reply":"2023-05-05T18:15:28.575891Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"document_lengths.describe()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iXZlO99C-UXK","outputId":"efed068a-5da6-4a30-b3e0-84ce2ef33aad","execution":{"iopub.status.busy":"2023-05-05T18:15:28.578157Z","iopub.execute_input":"2023-05-05T18:15:28.578501Z","iopub.status.idle":"2023-05-05T18:15:28.599221Z","shell.execute_reply.started":"2023-05-05T18:15:28.578469Z","shell.execute_reply":"2023-05-05T18:15:28.598388Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"count    100000.000000\nmean        662.352980\nstd         341.325023\nmin          18.000000\n25%         393.000000\n50%         612.000000\n75%         873.000000\nmax        1908.000000\ndtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"summary_lengths.describe()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ALMwKMx--ZF7","outputId":"f253ae1f-3034-4d06-dff8-379aa917003e","execution":{"iopub.status.busy":"2023-05-05T18:15:28.600429Z","iopub.execute_input":"2023-05-05T18:15:28.600797Z","iopub.status.idle":"2023-05-05T18:15:28.614206Z","shell.execute_reply.started":"2023-05-05T18:15:28.600764Z","shell.execute_reply":"2023-05-05T18:15:28.613110Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"count    100000.000000\nmean         46.397610\nstd          12.335318\nmin           7.000000\n25%          38.000000\n50%          46.000000\n75%          54.000000\nmax         474.000000\ndtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"# maxlen\n# taking values > and round figured to 75th percentile\n# at the same time not leaving high variance\nencoder_maxlen = 750\ndecoder_maxlen = 100","metadata":{"id":"cVeMilXr-bpC","execution":{"iopub.status.busy":"2023-05-05T18:15:28.618218Z","iopub.execute_input":"2023-05-05T18:15:28.618471Z","iopub.status.idle":"2023-05-05T18:15:28.624356Z","shell.execute_reply.started":"2023-05-05T18:15:28.618430Z","shell.execute_reply":"2023-05-05T18:15:28.623490Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"#### Tokenizing the texts into integer tokens","metadata":{"id":"95Zv7FIvKbTi"}},{"cell_type":"code","source":"# since < and > from default tokens cannot be removed\nfilters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\noov_token = '[UNK]'","metadata":{"id":"7TqbpEyPMRqa","execution":{"iopub.status.busy":"2023-05-05T18:15:28.627168Z","iopub.execute_input":"2023-05-05T18:15:28.627461Z","iopub.status.idle":"2023-05-05T18:15:28.633429Z","shell.execute_reply.started":"2023-05-05T18:15:28.627412Z","shell.execute_reply":"2023-05-05T18:15:28.632640Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\n    \"bert-base-cased\",\n    use_fast=True,\n    max_size = 2000,\n    unk_token=oov_token,\n)\n# Get the sos token\nsos_token = tokenizer.cls_token\n\n# Get the eos token\neos_token = tokenizer.sep_token","metadata":{"id":"TOjQOf13lswe","execution":{"iopub.status.busy":"2023-05-05T18:15:28.634622Z","iopub.execute_input":"2023-05-05T18:15:28.634870Z","iopub.status.idle":"2023-05-05T18:15:36.962659Z","shell.execute_reply.started":"2023-05-05T18:15:28.634841Z","shell.execute_reply":"2023-05-05T18:15:36.961745Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df527364c17d45b580430d10f9acc95c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd59a770334c497493048a127f0f27ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96b36bd7a4044ab9a2608721ddf493f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b41973ca1e14d9c85967cbf7dd2d24a"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Preprocessing before tokenizing","metadata":{"id":"yn4uWM0uI7wp"}},{"cell_type":"code","source":"# for decoder sequence\n# remove all the filters from documents\ndocument = document.apply(lambda x: x.translate(str.maketrans('', '', filters)))\n# remove numbers between words which are noisy as governme39ts\ndocument = document.apply(lambda x: re.sub(r'(?<=\\w)\\d+(?=\\w)', '', x))\n\n\n# remove all the filters from summaries and add sos and eos tokens\nsummary = summary.apply(lambda x: sos_token + ' ' + x.translate(str.maketrans('', '', filters)) + ' '+ eos_token)\n# remove numbers between words which are noisy as governme39ts\nsummary = summary.apply(lambda x: re.sub(r'(?<=\\w)\\d+(?=\\w)', '', x))\n\n\nsummary.head(), document.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lbKwzBrvI1SU","outputId":"75a197b1-f612-4e90-8395-8fc5827cd35c","execution":{"iopub.status.busy":"2023-05-05T18:15:36.964184Z","iopub.execute_input":"2023-05-05T18:15:36.964561Z","iopub.status.idle":"2023-05-05T18:16:05.199274Z","shell.execute_reply.started":"2023-05-05T18:15:36.964530Z","shell.execute_reply":"2023-05-05T18:16:05.198325Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(0    [CLS] Syrian official Obama climbed to the top...\n 1    [CLS] Usain Bolt wins third gold of world cham...\n 2    [CLS] The employee in agency's Kansas City off...\n 3    [CLS] NEW A Canadian doctor says she was part ...\n 4    [CLS] Another arrest made in gang rape outside...\n Name: highlights, dtype: object,\n 0    It's official US President Barack Obama wants ...\n 1    CNN  Usain Bolt rounded off the world champion...\n 2    Kansas City Missouri CNN  The General Services...\n 3    Los Angeles CNN  A medical doctor in Vancouver...\n 4    CNN  Police arrested another teen Thursday the...\n Name: article, dtype: object)"},"metadata":{}}]},{"cell_type":"code","source":"document[30], summary[30]","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:16:05.200722Z","iopub.execute_input":"2023-05-05T18:16:05.201070Z","iopub.status.idle":"2023-05-05T18:16:05.207684Z","shell.execute_reply.started":"2023-05-05T18:16:05.201039Z","shell.execute_reply":"2023-05-05T18:16:05.206643Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(\"CNN  The big winners of this Formula One season could be road drivers rather than F1 racers according to one former world champion Jody Scheckter who took the drivers' title in 19 hopes a raft of technological changes  notably smaller hybrid engines that promise greater fuel efficiency  will help improve road cars' performance It's very positive for the sport this is the first time you've seen the sport bring in regulations that really push the envelope of technology for every type of car the South African told CNN They are trying to take efficiency from everywhere they can on a car This year's race cars will boast an enhanced Energy Recovery System ERS and 1liter V6 engines compared to the 2liter Vs on show last year The ERS uses heat generated when braking and thermal energy from exhaust gases to create extra power The Kinetic Energy Recovery System KERS has been used in F1 since 29 but Scheckter says these latest advancements in the sport will only benefit everyday drivers Wherever there is heat they turn that into energy added the former Ferrari driver From that point of view that's what road cars are becoming more and more They've taken this energy from the brakes and these different areas that's what Formula One has done to a much higher degree than I've ever seen before I think the technology will flow to road cars very quickly It's very important for the global environment that they can make the technology work practically and then it can move into road cars On the track Scheckter expects an unpredictable start to the championship as teams and drivers wrestle with the new regulations An encouraging preseason for Mercedes has fueled talk that Lewis Hamilton is the favorite for this weekend's Australian Grand Prix and in pole position to take the title Hamilton a world champion in 28 set the fastest time on the final day of the final test event in Bahrain but the quickest lap time of preseason was set by Felipe Massa of Williams The Brazilian is a new arrival at the British team following nine years with Ferrari and Scheckter expects Massa and Hamilton to start well but he stopped short of tipping either to be top of the pile at the end of the season If you're going to follow some of the test results then you have to think that Mercedes and Williams have got an advantage at the beginning he said How long it will take for other teams to catch up who knows I would've thought after the fourth fifth race you might see things settle down Someone could make a modification and gain one second two seconds per lap That is a massive amount So until things settle down I wouldn't want to back anybody The climax of the 24 season is set to be a dramatic one with double points set to be awarded to the driver who takes the checkered flag at November's Abu Dhabi Grand Prix with the winner of that race awarded 50 points rather than the usual 25 It's a move that Scheckter thinks will see the fight for the world championship go down to the wire What they are trying to do is make it so the last race determines the championship he said If somebody is quite far ahead and it looks like he's going to win the championship  if he doesn't finish and another guy does he wins Is that fair No it's not but it makes exciting racing Or it makes you throw something at the TV Interactive 10 cars that changed Formula One \",\n \"[CLS] The first race of the 24 Formula One season takes place in Australia on Sunday Turbo engines are back in the sport with each car boasting a 1liter V6 hybrid Former F1 winner Jody Scheckter expects F1 technology to trickle down to road cars For the first time in the sport's history double points will be awarded at the year's final race  [SEP]\")"},"metadata":{}}]},{"cell_type":"code","source":"# Tokenize the strings\n# applying Padding/Truncating sequences for identical sequence lengths\ntokenized_data_inputs = [torch.tensor(tokenizer.encode(text, truncation=\"longest_first\", padding='max_length', max_length=encoder_maxlen, add_special_tokens=False)).to(device) for text in document]\ntokenized_data_outputs = [torch.tensor(tokenizer.encode(text, truncation=\"longest_first\", padding='max_length', max_length=decoder_maxlen, add_special_tokens=False)).to(device) for text in summary]\n\n# Define a function to tokenize a single document\n# def tokenize(text):\n#     return torch.tensor(tokenizer.encode(text, truncation=\"longest_first\", padding='max_length', max_length=encoder_maxlen, add_special_tokens=False)).to(device)\n\n# # Tokenize the data using the GPU\n# tokenized_data_inputs = [tokenize(text) for text in document]\n# tokenized_data_outputs = [tokenize(text) for text in summary]\n\n\n","metadata":{"id":"cHw2csoYImsa","execution":{"iopub.status.busy":"2023-05-05T18:16:05.209329Z","iopub.execute_input":"2023-05-05T18:16:05.209665Z","iopub.status.idle":"2023-05-05T18:20:53.156525Z","shell.execute_reply.started":"2023-05-05T18:16:05.209635Z","shell.execute_reply":"2023-05-05T18:20:53.155475Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Print the first encoded article and its summary\nprint(tokenized_data_inputs[0], tokenizer.decode(tokenized_data_inputs[0]))\nprint(tokenized_data_outputs[0], tokenizer.decode(tokenized_data_outputs[0]))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DWU9Xu7OKVab","outputId":"e8346e63-bc39-4c99-ffe5-58e10e25c20c","execution":{"iopub.status.busy":"2023-05-05T18:20:53.157862Z","iopub.execute_input":"2023-05-05T18:20:53.158199Z","iopub.status.idle":"2023-05-05T18:20:53.505121Z","shell.execute_reply.started":"2023-05-05T18:20:53.158168Z","shell.execute_reply":"2023-05-05T18:20:53.504161Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"tensor([ 1135,   112,   188,  2078,  1646,  1697, 14319,  7661,  3349,  1644,\n        11877,  1106, 18678,  1107,  1113,  2480,  1106,  1329,  1764,  2049,\n         1107,  7303,  7661,  1850,   170,  2998,  1106,  1103,  4075,  1104,\n         1103,  1585,  1105,  3279,  1113,  4306,  1480,  2005,  1170, 14563,\n         1115,  1119,  6616,  1764,  2168,  1222,  8697,  7539,  1110,  1103,\n         1268,  2585,  1106,  1321,  1166,  1103,  6351,  1329,  1104,  5297,\n         3595,  1109,  3000,  5626,  1121,  7661,  4390,  2757,  1106, 14942,\n         1103,  1329,  1104,  1764,  2049,  1106,  1260,  2083, 26499,  3843,\n         1105,  1260, 24633,  1103,  3209,  1111,  2174,  2745,  1104,  5297,\n         3595,  1137,  1168,  3595,  1104,  3367,  5915,  1135,   112,   188,\n          170,  2585,  1115,  1110,  1383,  1106,  1885,  1126,  1835,  5532,\n         1154,   170,  9250,  4500,  1741,  2321,  1247,  1132,  2501,  3243,\n        27003,  1166,  1103,  5655,  1327,  1225,  7414,  3595, 17672,  1116,\n         1525,  1107,  7303,  1327,  5940,  1191,  2757,  3667,  1185,  1262,\n         1293,  1209,  1103,  8697,  1433, 10573,  1130,   170, 14463,  4134,\n         1121,  1103,  2061,  1585,  3831,  5217,  2206,  4306,  1103,  2084,\n         1163,  1119,  1156,  1321,  1117,  1692,  1106,  2757,  1136,  1272,\n         1119,  1144,  1106,  1133,  1272,  1119,  3349,  1106,  1799,   146,\n         2059,   146,  1138,  1103,  3748,  1106,  3564,  1149,  1142,  1764,\n         2168,  1443,  2747, 10974, 25279,   146,  1221,  1115,  1103,  1583,\n         1209,  1129,  5992,  1191,  1195,  1321,  1142,  1736,  1105,  1412,\n         3721,  1209,  1129,  1256,  1167,  3903,  1119,  1163,  1284,  1431,\n         1138,  1142,  5655,  1272,  1103,  2492,  1132,  1315,  1992,  1111,\n         1671,  1112,  4400,  7661,  1163,  1499, 10974,  3478,  1125,  2675,\n         1106,  6030,   170,  5655,  1165,  1103,  1404,  5166,  1106,  1994,\n         1113,  1347,   130,  1109,  3279,  4201,  9269,  2341,  1209,  2080,\n          170,  4510,  1166,  1103,  2187,  1113,  9667, 14895,  1823,  3401,\n         6696,  6409,  1163, 13809, 13590, 15152,  7661,   112,   188,  1554,\n        13570,  8697,  5532,  6372,  2050,  9093,  7414, 17672,  1116,  1817,\n         7303,  7661,   112,   188, 13570,  1338,  3992,  1170,  7414, 17672,\n         1116,  1286,  7303,  4004,  2554,  1115,  1209,  4959,  2480,  5297,\n         3595,  1127,  1215,  1107,  1126,  2035,  1346,  1314,  1989,  1107,\n          170, 17065,  7144,  1109,  6457,  1104,  1103,  1342,  1303,  1103,\n        13515,  1110,  1304,  2330,  1105,  1115,  1110,  1106,  1112, 14840,\n        11379,  2480,  5297,  3595,  1127,  1215,  1105,  1136,  1118,  2292,\n         7414, 15465,  2405,   151, 18766, 15538,  1500, 13509,  1113,  4306,\n         1252,  1150,  1215,  1103,  3595,  1107,  1103,  2103, 12844,  3245,\n         2035,  1107,   170, 17065,  7144,  1113,  1360,  1626,  1144,  1151,\n          170,  2501,  1553,  1104,  4265,  5655,  1166,  1103,  8697,  5532,\n         3299,  1646,  3878,  1138,  1163,  1175,   112,   188,  1185,  4095,\n         1115,  1103,  8697,  1433,  1108,  1481,  1122,  1229,  8697,  3878,\n         1138,  5762,  4812,  1105, 11289, 23220,  9574,  3681,  2935,  1114,\n         1103,  9283,  1418,  1105,  1646,  4810,  3756,  1474,  1103,  2035,\n         2017,  5297,  3595,  1133,  7414,  3878,  1138, 13713,  1103,  4495,\n         1104,  2613,  1111,  1126,  2078,  2592,  1121, 17672,  1116,  1109,\n        17672,  1116,  1209,  2934,  1147,  9505,  1114,  7414,  2909,  2349,\n        24475,  1348, 18393,  4246,  6931, 18393,  1150,  1144,  1163,  1119,\n         3349,  1106,  3074,  1235,  1103,  7414,  1264,   112,   188,  1509,\n         2592,  1110,  2063,  1196, 11124,  1122,  1106,  1103,  7414,  4354,\n         1761,  1109,  6534,  1111,  1103,  5096, 16485,  1104, 10957, 20263,\n         1134,  2551,  1104,  1103, 17672,  1116,  6772,  1106,  1163,  4306,\n         1115,  1122,  1180,  1321,  1146,  1106,  1210,  2277,  1106, 19774,\n         1103,  2554,  1152,  4465,  1135,  2993,  1159,  1106,  1129,  1682,\n         1106, 19774,  1103,  1869,  1105,  1103,  8025,   151, 18766, 15538,\n         1163,  1124,  2382,  1115, 18393,  1144,  8038,  1163,  1175,  1110,\n         1185,  4174,  1106,   170,  1741,  5072,  1106,  1103,  5532,  1107,\n         7303,  1105,  1115,   170,  1764,  5072,  1110,  1136,  1126,  5146,\n        12889,  7303,  1110,   170,  2463,  1121,  2630,  1111,  1103,  1646,\n         7661,   112,  1188,  1441,  7954,  1538,  1129, 13367,   112,  7661,\n          112,   188,  2682, 14269,  1116,  1138, 16087,  1103,  1397,  3343,\n         1106,  1321,  1105,  1103,  2084,   112,   188,  7640,  4306,  1338,\n        15872, 17361,  1741,  2997,  1166,  1103,  2820,  1107,  7303,  1789,\n         1646,  1644, 11877,  1138,  1270,  1111,  5670,  2168,  1229,  1639,\n        11857,  1104,  9863,  1154,  1184,  1180,  1561,   170,   186,  6718,\n         1403, 15191,  1162,  1789,  4265,  3478,  1138,  4448,  1619,  1133,\n         1103,  1418,  2901,   112,   188,  2992,  1222,  1764,  2168,  2206,\n         1142,  1989,  1108,   170,  5993,  1106,  7661,   112,   188,  7816,\n         1104,  2033,  2012,  4581,  1121,  2501, 10017,  8224,  1212,  4306,\n         7661,  3000,  1184,  1119,  1163,  1156,  1129,   170,  2609,  1764,\n         2168,  1222,  8697,  1697, 18757,  5480,  1197,  2393, 23390, 23417,\n         6291,  1764,  2035,  1156,  1136,  1129,  1501, 15399,  1137,  1511,\n         1646,  1747,  2088,  1119,  1163,  7303,   112,   188,  6351,  1329,\n         1104,  5297,  3595,  2206,  1142,  2370,  1110,  1126,  5937,  1113,\n         1769, 14931,  1103,  2084,  1163,   138,  4290,  1106,  6297,  1114,\n         2049,  7661,  4491,  1180,  1730,  1106, 13936,  7867,  3798,  1329],\n       device='cuda:0') It's official US President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria Obama sent a letter to the heads of the House and Senate on Saturday night hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons The proposed legislation from Obama asks Congress to approve the use of military force to deter disrupt prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction It's a step that is set to turn an international crisis into a fierce domestic political battle There are key questions looming over the debate What did UN weapons inspectors find in Syria What happens if Congress votes no And how will the Syrian government react In a televised address from the White House Rose Garden earlier Saturday the president said he would take his case to Congress not because he has to but because he wants to While I believe I have the authority to carry out this military action without specific congressional authorization I know that the country will be stronger if we take this course and our actions will be even more effective he said We should have this debate because the issues are too big for business as usual Obama said top congressional leaders had agreed to schedule a debate when the body returns to Washington on September 9 The Senate Foreign Relations Committee will hold a hearing over the matter on Tuesday Sen Robert Menendez said Transcript Read Obama's full remarks Syrian crisis Latest developments UN inspectors leave Syria Obama's remarks came shortly after UN inspectors left Syria carrying evidence that will determine whether chemical weapons were used in an attack early last week in a Damascus suburb The aim of the game here the mandate is very clear and that is to ascertain whether chemical weapons were used and not by whom UN spokesman Martin Nesirky told reporters on Saturday But who used the weapons in the reported toxic gas attack in a Damascus suburb on August 21 has been a key point of global debate over the Syrian crisis Top US officials have said there's no doubt that the Syrian government was behind it while Syrian officials have denied responsibility and blamed jihadists fighting with the rebels British and US intelligence reports say the attack involved chemical weapons but UN officials have stressed the importance of waiting for an official report from inspectors The inspectors will share their findings with UN SecretaryGeneral Ban Kimoon Ban who has said he wants to wait until the UN team's final report is completed before presenting it to the UN Security Council The Organization for the Prohibition of Chemical Weapons which nine of the inspectors belong to said Saturday that it could take up to three weeks to analyze the evidence they collected It needs time to be able to analyze the information and the samples Nesirky said He noted that Ban has repeatedly said there is no alternative to a political solution to the crisis in Syria and that a military solution is not an option Bergen Syria is a problem from hell for the US Obama'This menace must be confronted'Obama's senior advisers have debated the next steps to take and the president's comments Saturday came amid mounting political pressure over the situation in Syria Some US lawmakers have called for immediate action while others warn of stepping into what could become a quagmire Some global leaders have expressed support but the British Parliament's vote against military action earlier this week was a blow to Obama's hopes of getting strong backing from key NATO allies On Saturday Obama proposed what he said would be a limited military action against Syrian President Bashar alAssad Any military attack would not be openended or include US ground forces he said Syria's alleged use of chemical weapons earlier this month is an assault on human dignity the president said A failure to respond with force Obama argued could lead to escalating use\ntensor([  101,  8697,  2078,  7661,  5998,  1106,  1103,  1499,  1104,  1103,\n         2780,  2144,   112,   189,  1221,  1293,  1106,  1243,  1205,  2346,\n         2822,  1918, 10130,   170,  2998,  1106,  1103,  4075,  1104,  1103,\n         1585,  1105,  3279,  7661,  1106,  5622, 10974,  5684,  1113,  1764,\n         2168,  1222,  7303, 19294,  1306,  1110,  1106,  4959,  2480, 21303,\n         1127,  1215,  1136,  1118,  2292,  1867,  7414, 15465,   102,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n       device='cuda:0') [CLS] Syrian official Obama climbed to the top of the tree doesn't know how to get downObama sends a letter to the heads of the House and Senate Obama to seek congressional approval on military action against Syria Aim is to determine whether CW were used not by whom says UN spokesman [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","output_type":"stream"}]},{"cell_type":"code","source":"len(tokenized_data_inputs[0])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ESm-aYR-tvx","outputId":"4a67b85b-356b-41bb-cc7b-79a40ea064af","execution":{"iopub.status.busy":"2023-05-05T18:20:53.506611Z","iopub.execute_input":"2023-05-05T18:20:53.507192Z","iopub.status.idle":"2023-05-05T18:20:53.515974Z","shell.execute_reply.started":"2023-05-05T18:20:53.507159Z","shell.execute_reply":"2023-05-05T18:20:53.515116Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"750"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.encode(\"This is a test\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kVyErXAei5_b","outputId":"6a10e573-5d9b-420f-b55c-703f62e60292","execution":{"iopub.status.busy":"2023-05-05T18:20:53.517700Z","iopub.execute_input":"2023-05-05T18:20:53.518187Z","iopub.status.idle":"2023-05-05T18:20:53.526385Z","shell.execute_reply.started":"2023-05-05T18:20:53.518157Z","shell.execute_reply":"2023-05-05T18:20:53.525455Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"[101, 1188, 1110, 170, 2774, 102]"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode([101, 1188, 1110, 170, 2774, 102])","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Ryx9qx90jwXu","outputId":"93ade241-cc3e-41b0-ca66-3d02a45229af","execution":{"iopub.status.busy":"2023-05-05T18:20:53.527512Z","iopub.execute_input":"2023-05-05T18:20:53.528222Z","iopub.status.idle":"2023-05-05T18:20:53.534518Z","shell.execute_reply.started":"2023-05-05T18:20:53.528187Z","shell.execute_reply":"2023-05-05T18:20:53.533600Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"'[CLS] This is a test [SEP]'"},"metadata":{}}]},{"cell_type":"code","source":"vocab_size = tokenizer.vocab_size\nvocab_size","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KoizyBvLKv8h","outputId":"45313f5a-9354-4c30-8513-d0fb88e284c7","execution":{"iopub.status.busy":"2023-05-05T18:20:53.535602Z","iopub.execute_input":"2023-05-05T18:20:53.536384Z","iopub.status.idle":"2023-05-05T18:20:53.543639Z","shell.execute_reply.started":"2023-05-05T18:20:53.536342Z","shell.execute_reply":"2023-05-05T18:20:53.542641Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"28996"},"metadata":{}}]},{"cell_type":"markdown","source":"### Creating dataset pipeline","metadata":{"id":"wIP0kIIcB8Rm"}},{"cell_type":"code","source":"\nclass MyDataset(Dataset):\n    def __init__(self, inputs, targets):\n        self.inputs = inputs\n        self.targets = targets\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, idx):\n        return self.inputs[idx], self.targets[idx]\n\nbatch_size = 64\nshuffle = 20000\n\ndataset = MyDataset(tokenized_data_inputs, tokenized_data_outputs)\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n","metadata":{"id":"wI-fV7eABWN6","execution":{"iopub.status.busy":"2023-05-05T18:20:53.544754Z","iopub.execute_input":"2023-05-05T18:20:53.545507Z","iopub.status.idle":"2023-05-05T18:20:53.582297Z","shell.execute_reply.started":"2023-05-05T18:20:53.545474Z","shell.execute_reply":"2023-05-05T18:20:53.581549Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"for inputs, outputs in dataloader:\n    print(len(inputs), len(inputs[0]))\n    print(len(outputs), len(outputs[0]))\n    break","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pq4N5KSMlswi","outputId":"e4da2267-fb3c-4b97-b385-f271b948f94b","execution":{"iopub.status.busy":"2023-05-05T18:20:53.584290Z","iopub.execute_input":"2023-05-05T18:20:53.585165Z","iopub.status.idle":"2023-05-05T18:20:53.630424Z","shell.execute_reply.started":"2023-05-05T18:20:53.585135Z","shell.execute_reply":"2023-05-05T18:20:53.629548Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"64 750\n64 100\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Masking\n\n- Padding mask for masking \"pad\" sequences\n- Lookahead mask for masking future words from contributing in prediction of current words in self attention","metadata":{"id":"24Pe01DMMWHc"}},{"cell_type":"code","source":"def create_padding_mask(input_sequence):\n    # input_sequence : B, T\n    mask = (input_sequence != 0).unsqueeze(-2).float()\n    return mask\n\n# # B, T, T\n# mask = create_padding_mask(inputs[0:2])\n# tx = torch.randn(2, 10, 10).to('cuda')\n# tx = tx.masked_fill(mask == 0, float('-inf'))\n# mask","metadata":{"id":"hN1wVQAdMVYy","execution":{"iopub.status.busy":"2023-05-05T18:20:53.631889Z","iopub.execute_input":"2023-05-05T18:20:53.632220Z","iopub.status.idle":"2023-05-05T18:20:53.637140Z","shell.execute_reply.started":"2023-05-05T18:20:53.632190Z","shell.execute_reply":"2023-05-05T18:20:53.635981Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def create_look_ahead_mask(size):\n    return torch.tril(torch.ones(size, size, device=device))\n\n# create_look_ahead_mask(3)","metadata":{"id":"UmjAPLWuMREE","execution":{"iopub.status.busy":"2023-05-05T18:20:53.638775Z","iopub.execute_input":"2023-05-05T18:20:53.639148Z","iopub.status.idle":"2023-05-05T18:20:53.646240Z","shell.execute_reply.started":"2023-05-05T18:20:53.639099Z","shell.execute_reply":"2023-05-05T18:20:53.645262Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### Building the Model","metadata":{"id":"n8DqUBc4NFOy"}},{"cell_type":"code","source":"# tril = torch.tril(torch.ones(8, 8))\n\n# T = 3\n# wei = torch.ones(T, T) * 5\n# wei = wei.masked_fill(tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n# tril, wei","metadata":{"id":"dsjM1jZrlswk","execution":{"iopub.status.busy":"2023-05-05T18:20:53.647862Z","iopub.execute_input":"2023-05-05T18:20:53.648198Z","iopub.status.idle":"2023-05-05T18:20:53.654248Z","shell.execute_reply.started":"2023-05-05T18:20:53.648146Z","shell.execute_reply":"2023-05-05T18:20:53.653377Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"#### Hyperparameters","metadata":{"id":"l3QBgq90lswk"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\n\n# hyperparameters\nbatch_size = 32 # how many independent sequences will we process in parallel?\nencoder_block_size = encoder_maxlen # what is the maximum context length for predictions?\ndecoder_block_size = decoder_maxlen # what is the maximum context length for predictions?\nmax_iters = 10000\neval_interval = 500\nlearning_rate = 1e-3\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(device)\neval_iters = 100\nn_embd = 192\nn_head = 6\nn_layer = 3\ndropout = 0.2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ut0IP2glswl","outputId":"101cb070-3e53-40c6-d731-10dc0c01178e","execution":{"iopub.status.busy":"2023-05-05T18:20:53.655868Z","iopub.execute_input":"2023-05-05T18:20:53.656309Z","iopub.status.idle":"2023-05-05T18:20:53.664011Z","shell.execute_reply.started":"2023-05-05T18:20:53.656195Z","shell.execute_reply":"2023-05-05T18:20:53.662827Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Head","metadata":{"id":"cZT-PAZ6lswl"}},{"cell_type":"code","source":"class Head(nn.Module):\n    \"\"\" one head of self-attention \"\"\"\n\n    def __init__(self, head_size):\n        super().__init__()\n        self.key = nn.Linear(n_embd, head_size, bias=False)\n        self.query = nn.Linear(n_embd, head_size, bias=False)\n        self.value = nn.Linear(n_embd, head_size, bias=False)\n        self.head_size = head_size\n        \n        # TODO: move this tril to decoder block and pass it in ma attention better as a mask\n        # I'm creating this Trill variable Trill is not a parameter of the module so in sort of pytorch\n        # conventions this is called a buffer it's not a parameter and you have to call it you have to assign it to the module\n        # using a register buffer so that creates the trail, the triangle lower triangular Matrix\n        # self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n\n        # we can also drop out here when we calculate the basically affinities and after the softmax we can drop out\n        # some of those so we can randomly prevent some of the nodes from communicating\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, mask, key_value = None):\n        B,T,C = x.shape\n        if key_value is None:\n            # key_value will be None if its self attention, but will be with value if it comes from other source as cross attention \n            key_value = x\n\n        k = self.key(key_value)   # (B,T,C)\n        q = self.query(x) # (B,T,C)\n        # compute attention scores (\"affinities\")\n        wei = q @ k.transpose(-2,-1) * self.head_size**-0.5  # (B, T, C) @ (B, C, T) -> (B, T, T)\n        wei = wei.masked_fill(mask[:T, :T] == 0, float('-inf')) # (B, T, T)\n        wei = F.softmax(wei, dim=-1) # (B, T, T)\n        wei = self.dropout(wei)\n        # perform the weighted aggregation of the values\n        v = self.value(key_value) # (B,T,C)\n        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n        return out","metadata":{"id":"t2PtQxe1lswm","execution":{"iopub.status.busy":"2023-05-05T18:20:53.665804Z","iopub.execute_input":"2023-05-05T18:20:53.666195Z","iopub.status.idle":"2023-05-05T18:20:53.676581Z","shell.execute_reply.started":"2023-05-05T18:20:53.666166Z","shell.execute_reply":"2023-05-05T18:20:53.675622Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"#### Multi-Headed Attention","metadata":{"id":"Rf7_a5uQOfJk"}},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    \"\"\" multiple heads of self-attention in parallel \"\"\"\n\n    def __init__(self, num_heads, head_size):\n        super().__init__()\n        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n        # a linear transformation layer that projects the concatenated output from the self.heads module to the original embedding size n_embd.\n        self.proj = nn.Linear(n_embd, n_embd)\n        \n        # a dropout layer that randomly sets some of the output values to zero during training to prevent overfitting.\n        # Dropout is something that you can add right before the residual connection back or right before the connection back into the original pathway\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, mask, key_value = None):\n        # mask : mask we will be applying for each head\n        # key_value : can be passed in case of cross attention.\n\n        # we run all of the heads in parallel into a list and simply concatenate all of the outputs and we're concatenating over the channel dimension\n        out = torch.cat([h(x, mask, key_value) for h in self.heads], dim=-1)\n        out = self.dropout(self.proj(out))\n        return out","metadata":{"id":"iIuFrdXnNZEC","execution":{"iopub.status.busy":"2023-05-05T18:20:53.682851Z","iopub.execute_input":"2023-05-05T18:20:53.683112Z","iopub.status.idle":"2023-05-05T18:20:53.690741Z","shell.execute_reply.started":"2023-05-05T18:20:53.683091Z","shell.execute_reply":"2023-05-05T18:20:53.689846Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"### Feed Forward Network","metadata":{"id":"A49tXMVvOkOZ"}},{"cell_type":"code","source":"\n\nclass FeedFoward(nn.Module):\n    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n\n    def __init__(self, n_embd):\n        super().__init__()\n        # The module is defined using the PyTorch nn.Sequential class, which allows us to define a sequence of layers that are applied to the input in order.\n        # a feedforward neural network module with two linear layers, a ReLU activation function, and a dropout layer. \n        self.net = nn.Sequential(\n            nn.Linear(n_embd, 4 * n_embd),\n            nn.ReLU(),\n            nn.Linear(4 * n_embd, n_embd),\n            # a dropout layer that randomly sets some of the output values to zero during training to prevent overfitting.\n            nn.Dropout(dropout),\n        )\n\n    def forward(self, x):\n        return self.net(x)","metadata":{"id":"d9-qoKuTNwKq","execution":{"iopub.status.busy":"2023-05-05T18:20:53.692263Z","iopub.execute_input":"2023-05-05T18:20:53.692656Z","iopub.status.idle":"2023-05-05T18:20:53.701173Z","shell.execute_reply.started":"2023-05-05T18:20:53.692626Z","shell.execute_reply":"2023-05-05T18:20:53.700308Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"#### Fundamental Unit of Transformer encoder","metadata":{"id":"B2RRmn2bOpW9"}},{"cell_type":"code","source":"class EncoderLayer(nn.Module):\n    \"\"\" Transformer block: communication followed by computation \"\"\"\n\n    def __init__(self, n_embd, n_head):\n        # n_embd: embedding dimension, n_head: the number of heads we'd like\n        super().__init__()\n        head_size = n_embd // n_head\n        # n_head heads each of head_size-dimensional self attention running in parallel\n        self.sa = MultiHeadAttention(n_head, head_size)\n\n        # feedforward neural network purpose: before when we had the multi-headed self-attention only that did the communication, we went way too fast\n        # to calculate the logits so the tokens looked at each other but didn't really have a lot of time to think on what they found from the other tokens\n        # notice: that the feed forward here when it's applying linear this is on a per token level all the tokens do this independently so the self-attention is the communication and \n        # then once they've gathered all the data now they need to think on that data individually and so that's what feed forward is doing\n        self.ffwd = FeedFoward(n_embd)\n\n        # the size of the layer Norm here is n_embd of 32. so when the layer Norm is normalizing our features it is the normalization here\n        # happens the mean and the variance are taking over 32 numbers so the batch and the time act as batch Dimensions both of\n        # them so this is kind of like a per token transformation that just normalizes the features and makes them a unit mean unit gaussian at initialization\n        self.ln1 = nn.LayerNorm(n_embd)\n        self.ln2 = nn.LayerNorm(n_embd)\n\n    def forward(self, x, mask):\n        # this is actually something that slightly departs from the original paper you see that the [ADD and Norm] is applied after the transformation\n        # but um in now it is a bit more basically common to apply the layer Norm before the transformation so there's a reshuffling of the layer Norms \n        # so this is called the [pre-norm formulation] and that's the one that we're going to implement as well\n        x = x + self.sa(self.ln1(x), mask)\n        x = x + self.ffwd(self.ln2(x))\n        return x\n","metadata":{"id":"HNuoJoFWO335","execution":{"iopub.status.busy":"2023-05-05T18:20:53.702802Z","iopub.execute_input":"2023-05-05T18:20:53.703588Z","iopub.status.idle":"2023-05-05T18:20:53.710691Z","shell.execute_reply.started":"2023-05-05T18:20:53.703554Z","shell.execute_reply":"2023-05-05T18:20:53.709912Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"#### Fundamental Unit of Transformer decoder","metadata":{"id":"9i6Zh8gnPqdW"}},{"cell_type":"code","source":"class DecoderLayer(nn.Module):\n    \"\"\" Transformer block: communication followed by computation \"\"\"\n\n    def __init__(self, n_embd, n_head):\n        # n_embd: embedding dimension, n_head: the number of heads we'd like\n        super().__init__()\n        head_size = n_embd // n_head\n        # n_head heads each of head_size-dimensional self attention running in parallel\n        self.self_attention = MultiHeadAttention(n_head, head_size)\n        \n        # cross attention\n        self.cross_attention = MultiHeadAttention(n_head, head_size)\n        \n        # feedforward neural network purpose: before when we had the multi-headed self-attention only that did the communication, we went way too fast\n        # to calculate the logits so the tokens looked at each other but didn't really have a lot of time to think on what they found from the other tokens\n        # notice: that the feed forward here when it's applying linear this is on a per token level all the tokens do this independently so the self-attention is the communication and \n        # then once they've gathered all the data now they need to think on that data individually and so that's what feed forward is doing\n        self.ffwd = FeedFoward(n_embd)\n\n        # the size of the layer Norm here is n_embd of 32. so when the layer Norm is normalizing our features it is the normalization here\n        # happens the mean and the variance are taking over 32 numbers so the batch and the time act as batch Dimensions both of\n        # them so this is kind of like a per token transformation that just normalizes the features and makes them a unit mean unit gaussian at initialization\n        self.ln1 = nn.LayerNorm(n_embd)\n        self.ln2 = nn.LayerNorm(n_embd)\n        self.ln3 = nn.LayerNorm(n_embd)\n\n\n    def forward(self, x, encoder_mask, decoder_mask, encoder_output):\n        # this is actually something that slightly departs from the original paper you see that the [ADD and Norm] is applied after the transformation\n        # but um in now it is a bit more basically common to apply the layer Norm before the transformation so there's a reshuffling of the layer Norms \n        # so this is called the [pre-norm formulation] and that's the one that we're going to implement as well\n        x = x + self.self_attention(self.ln1(x), decoder_mask)\n        x = x + self.cross_attention(self.ln2(x), encoder_mask, encoder_output)\n        x = x + self.ffwd(self.ln3(x))\n        return x\n\n","metadata":{"id":"7CVmvs6dPMRC","execution":{"iopub.status.busy":"2023-05-05T18:20:53.712088Z","iopub.execute_input":"2023-05-05T18:20:53.712707Z","iopub.status.idle":"2023-05-05T18:20:53.723792Z","shell.execute_reply.started":"2023-05-05T18:20:53.712675Z","shell.execute_reply":"2023-05-05T18:20:53.723120Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"#### Encoder consisting of multiple EncoderLayer(s)","metadata":{"id":"6zt5MUc_QNid"}},{"cell_type":"code","source":"class Encoder(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        # each token directly reads off the logits for the next token from a lookup table\n        # take care now embedding size (= n_embd) != vocab size \n        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n        # positional encoding lookup \n        self.position_embedding_table = nn.Embedding(encoder_block_size, n_embd)\n\n        self.blocks = nn.Sequential(*[EncoderLayer(n_embd, n_head) for _ in range(n_layer)])\n        \n\n    def forward(self, idx, encoder_mask):\n        B, T = idx.shape\n\n        # idx is both (B,T) tensor of integers\n        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n        \n        # now total embedding = token embedding + positional embedding\n        x = tok_emb + pos_emb # (B,T,C)\n        \n        # pass x into\n        for i in range(n_layer):\n            x = self.blocks[i](x, encoder_mask) # (B,T,C)\n        return x","metadata":{"id":"BrbnTwijQJ-h","execution":{"iopub.status.busy":"2023-05-05T18:20:53.725045Z","iopub.execute_input":"2023-05-05T18:20:53.725664Z","iopub.status.idle":"2023-05-05T18:20:53.735536Z","shell.execute_reply.started":"2023-05-05T18:20:53.725633Z","shell.execute_reply":"2023-05-05T18:20:53.734939Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"#### Decoder consisting of multiple DecoderLayer(s)","metadata":{"id":"4N5LrNrvRexg"}},{"cell_type":"code","source":"class Decoder(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        # each token directly reads off the logits for the next token from a lookup table\n        # take care now embedding size (= n_embd) != vocab size \n        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n        # positional encoding lookup \n        self.position_embedding_table = nn.Embedding(decoder_block_size, n_embd)\n\n        self.blocks = nn.Sequential(*[DecoderLayer(n_embd, n_head=n_head) for _ in range(n_layer)])\n\n    def forward(self, idx, encoder_mask, decoder_mask, encoder_output):\n        B, T = idx.shape\n\n        # idx is both (B,T) tensor of integers\n        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n        \n        # now total embedding = token embedding + positional embedding\n        x = tok_emb + pos_emb # (B,T,C)\n        \n        # pass x into\n        # pass x into\n        for i in range(n_layer):\n          x = self.blocks[i](x, encoder_mask, decoder_mask, encoder_output) # (B,T,C)\n        return x","metadata":{"id":"UmeqkZrIRbSB","execution":{"iopub.status.busy":"2023-05-05T18:20:53.737031Z","iopub.execute_input":"2023-05-05T18:20:53.737712Z","iopub.status.idle":"2023-05-05T18:20:53.745074Z","shell.execute_reply.started":"2023-05-05T18:20:53.737678Z","shell.execute_reply":"2023-05-05T18:20:53.744342Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"#### Finally, the Transformer","metadata":{"id":"lbMNK_bzSHnh"}},{"cell_type":"code","source":"\nclass Transformer(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        \n        self.encoder = Encoder()\n        self.decoder = Decoder()\n        # final layer norm at the end of the transfomer\n        self.ln_f = nn.LayerNorm(n_embd)\n        \n        # a fully connected (linear) layer by performing a linear transformation on the input tensor\n        # with a weight matrix of size (n_embd, vocab_size) and adding a bias vector of size (vocab_size,)\n        self.lm_head = nn.Linear(n_embd, vocab_size)\n\n    def forward(self, encoder_input_idx, encoding_mask, decoder_input_idx, decoder_target_idx, decoder_mask):\n        \n        encoder_output = self.encoder(encoder_input_idx, encoding_mask)\n\n        decoder_output = self.decoder(decoder_input_idx, encoding_mask, decoder_mask, encoder_output)\n\n\n        # pass x into\n        decoder_output = self.ln_f(decoder_output) # (B,T,C)\n\n\n        # logits is the ouput of the fully connected (linear) layer now given input decoder_output\n        logits = self.lm_head(decoder_output) # (B,T,vocab_size)\n        \n        if decoder_target_idx is None:\n            loss = None\n        else:\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            decoder_target_idx = decoder_target_idx.reshape(B*T)\n            mask = (decoder_target_idx != 0) # create a mask of non-padding tokens\n            loss = F.cross_entropy(logits[mask], decoder_target_idx[mask])\n\n        return logits, loss\n    \n    def generate(self, idx, max_new_tokens):\n        # idx is (B, T) array of indices in the current context\n        for _ in range(max_new_tokens):\n\n            # because now we're using positional embeddings we can never have more than block size coming in because if idx is\n            # more than block size then our position embedding table is going to run out of scope because it only has embeddings for up to block size \n            # crop idx to the last block_size tokens\n            idx_cond = idx[:, -decoder_block_size:]\n            # get the predictions\n            logits, loss = self(idx_cond)\n            # focus only on the last time step\n            logits = logits[:, -1, :] # becomes (B, C)\n            # apply softmax to get probabilities\n            probs = F.softmax(logits, dim=-1) # (B, C)\n            # sample from the distribution\n            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n            # append sampled index to the running sequence\n            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n        return idx\n\n\n","metadata":{"id":"FXHRG-o4R9Mc","execution":{"iopub.status.busy":"2023-05-05T18:20:53.746317Z","iopub.execute_input":"2023-05-05T18:20:53.746937Z","iopub.status.idle":"2023-05-05T18:20:53.758018Z","shell.execute_reply.started":"2023-05-05T18:20:53.746906Z","shell.execute_reply":"2023-05-05T18:20:53.757347Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"#### Adam optimizer with custom learning rate scheduling","metadata":{"id":"uOGvkYDNTjIj"}},{"cell_type":"code","source":"# class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n#     def __init__(self, d_model, warmup_steps=4000):\n#         super(CustomSchedule, self).__init__()\n\n#         self.d_model = d_model\n#         self.d_model = tf.cast(self.d_model, tf.float32)\n\n#         self.warmup_steps = warmup_steps\n    \n#     def __call__(self, step):\n#         arg1 = tf.math.rsqrt(step)\n#         arg2 = step * (self.warmup_steps ** -1.5)\n\n#         return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n","metadata":{"id":"tfiynCLlTL8C","execution":{"iopub.status.busy":"2023-05-05T18:20:53.759290Z","iopub.execute_input":"2023-05-05T18:20:53.759900Z","iopub.status.idle":"2023-05-05T18:20:53.768999Z","shell.execute_reply.started":"2023-05-05T18:20:53.759870Z","shell.execute_reply":"2023-05-05T18:20:53.768392Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"model = Transformer()\nm = model.to(device)","metadata":{"id":"5Ia0pqLUlsws","execution":{"iopub.status.busy":"2023-05-05T18:20:53.770243Z","iopub.execute_input":"2023-05-05T18:20:53.770944Z","iopub.status.idle":"2023-05-05T18:20:54.023751Z","shell.execute_reply.started":"2023-05-05T18:20:53.770904Z","shell.execute_reply":"2023-05-05T18:20:54.022801Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"#### Masks","metadata":{"id":"f56BGiVXU_Dk"}},{"cell_type":"code","source":"def create_masks(input, target):\n    encoder_mask = create_padding_mask(input)\n    look_ahead_mask = create_look_ahead_mask(target.shape[1])\n    dec_target_padding_mask = create_padding_mask(target)\n    decoder_mask = torch.minimum(dec_target_padding_mask, look_ahead_mask)\n  \n    return encoder_mask, decoder_mask\n","metadata":{"id":"FZxHuyZxU5Pa","execution":{"iopub.status.busy":"2023-05-05T18:20:54.025253Z","iopub.execute_input":"2023-05-05T18:20:54.025627Z","iopub.status.idle":"2023-05-05T18:20:54.030576Z","shell.execute_reply.started":"2023-05-05T18:20:54.025594Z","shell.execute_reply":"2023-05-05T18:20:54.029701Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"#### Defining losses and other metrics ","metadata":{"id":"DsVdrENTUERY"}},{"cell_type":"code","source":"# data loading\ndef get_batch():#split):\n    # generate a small batch of data of inputs x and targets y\n    # data = train_data if split == 'train' else val_data\n    batch = random.choice(list(dataloader))\n    x, y = batch\n    x, y = x.to(device), y.to(device)\n    return x, y\n\n\n# @torch.no_grad() this line says to pytorch to prevent backprop since we will be evaluating not real training\n@torch.no_grad()\ndef estimate_loss():\n    out = {}\n    # let model be in evaluation phase so layers like normalization, .. change their behaviour at inference time\n    model.eval()\n    for split in ['train']: #, 'val']:\n        losses = torch.zeros(eval_iters)\n        for k in range(eval_iters):\n            X, Y = get_batch() #split)\n            target_input = Y[:, :-1]\n            target_real = Y[:, 1:]\n            encoder_mask, decoder_mask = create_masks(X, target_input)\n            logits, loss = model(X, encoder_mask, target_input, target_real, decoder_mask)\n                                \n            losses[k] = loss.item()\n        out[split] = losses.mean()\n    # back to training phase\n    model.train()\n    return out\n\n  \n    \n    \n ","metadata":{"id":"yWZQgk-9lswu","execution":{"iopub.status.busy":"2023-05-05T18:20:54.032052Z","iopub.execute_input":"2023-05-05T18:20:54.032669Z","iopub.status.idle":"2023-05-05T18:20:54.040945Z","shell.execute_reply.started":"2023-05-05T18:20:54.032639Z","shell.execute_reply":"2023-05-05T18:20:54.039993Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# learning_rate = CustomSchedule(float(d_model))\n# optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n\n# print the number of parameters in the model\nprint(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n\n# create a PyTorch optimizer\noptimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ip1-943kTXXK","outputId":"84386ebe-fbd2-4da9-e8d9-1125932f954a","execution":{"iopub.status.busy":"2023-05-05T18:20:54.042254Z","iopub.execute_input":"2023-05-05T18:20:54.042582Z","iopub.status.idle":"2023-05-05T18:20:54.052661Z","shell.execute_reply.started":"2023-05-05T18:20:54.042553Z","shell.execute_reply":"2023-05-05T18:20:54.051727Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"20.0041 M parameters\n","output_type":"stream"}]},{"cell_type":"code","source":"# loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n# def loss_function(real, pred):\n#     mask = tf.math.logical_not(tf.math.equal(real, 0))\n#     loss_ = loss_object(real, pred)\n\n#     mask = tf.cast(mask, dtype=loss_.dtype)\n#     loss_ *= mask\n\n#     return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n","metadata":{"id":"uW4LA_45T4Aa","execution":{"iopub.status.busy":"2023-05-05T18:20:54.053795Z","iopub.execute_input":"2023-05-05T18:20:54.054216Z","iopub.status.idle":"2023-05-05T18:20:54.064357Z","shell.execute_reply.started":"2023-05-05T18:20:54.054186Z","shell.execute_reply":"2023-05-05T18:20:54.063559Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# train_loss = tf.keras.metrics.Mean(name='train_loss')","metadata":{"id":"Ze0u6xxXT7dI","execution":{"iopub.status.busy":"2023-05-05T18:20:54.065719Z","iopub.execute_input":"2023-05-05T18:20:54.066030Z","iopub.status.idle":"2023-05-05T18:20:54.073038Z","shell.execute_reply.started":"2023-05-05T18:20:54.066001Z","shell.execute_reply":"2023-05-05T18:20:54.072183Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"#### Transformer","metadata":{"id":"9XvKy3v6ULnO"}},{"cell_type":"markdown","source":"#### Checkpoints","metadata":{"id":"SYIotvaBVI0d"}},{"cell_type":"code","source":"!pwd","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:20:54.075530Z","iopub.execute_input":"2023-05-05T18:20:54.075908Z","iopub.status.idle":"2023-05-05T18:20:55.142519Z","shell.execute_reply.started":"2023-05-05T18:20:54.075879Z","shell.execute_reply":"2023-05-05T18:20:55.141426Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"# checkpoint_path = \"checkpoints\"\n\n# ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n\n# ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n\n# if ckpt_manager.latest_checkpoint:\n#     ckpt.restore(ckpt_manager.latest_checkpoint)\n#     print ('Latest checkpoint restored!!')\n\ncheckpoint_path = \"/kaggle/working/models/model.pt\"\n\ndef save(epoch, model, optimizer, loss):\n  checkpoint = {\n      'epoch': epoch,\n      'model_state_dict': model.state_dict(),\n      'optimizer_state_dict': optimizer.state_dict(),\n      'loss': loss,\n  }\n  torch.save(checkpoint, checkpoint_path)\n\ndef load():\n  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n  model = Transformer().to(device)  # create an instance of your model\n  optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n  \n  checkpoint = torch.load(checkpoint_path, map_location=device)\n  model.load_state_dict(checkpoint['model_state_dict'])\n  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n  epoch = checkpoint['epoch']\n  loss = checkpoint['loss']\n\n  model.to(device)\n  return model, optimizer, epoch, loss","metadata":{"id":"tOc1_3c-VGaL","execution":{"iopub.status.busy":"2023-05-05T18:56:05.627299Z","iopub.execute_input":"2023-05-05T18:56:05.627694Z","iopub.status.idle":"2023-05-05T18:56:05.635180Z","shell.execute_reply.started":"2023-05-05T18:56:05.627664Z","shell.execute_reply":"2023-05-05T18:56:05.634188Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"#### Training steps","metadata":{"id":"WfpI0gS4c06c"}},{"cell_type":"code","source":"def train_step(input, target):\n    target_input = target[:, :-1]\n    target_real = target[:, 1:]\n\n    encoder_mask, decoder_mask = create_masks(input, target_input)\n    \n    \n    logits, loss = model(\n        input,\n        encoder_mask,\n        target_input,\n        target_real,\n        decoder_mask,\n    )\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n    optimizer.step()","metadata":{"id":"xmVOMzkrczgl","execution":{"iopub.status.busy":"2023-05-05T18:57:04.388454Z","iopub.execute_input":"2023-05-05T18:57:04.388846Z","iopub.status.idle":"2023-05-05T18:57:04.395861Z","shell.execute_reply.started":"2023-05-05T18:57:04.388817Z","shell.execute_reply":"2023-05-05T18:57:04.394811Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"for epoch in range(5):\n    start = time.time()\n\n    # train_loss.reset_states()\n    for (batch, (inputs, outputs)) in enumerate(dataloader):\n        \n        # (inputs, outputs) here represent batch of examples\n        # inputs: Batch_size * input_sequence_length\n        # outputs: Batch_size * output_sequence_length\n        \n        # every once in a while evaluate the loss on train and val sets\n        if batch % eval_interval == 0 or batch == max_iters - 1:\n            losses = estimate_loss()\n            print(f\"step {batch}: train loss {losses['train']:.4f}\") #, val loss {losses['val']:.4f}\")\n        \n        \n        train_step(inputs, outputs)\n     \n    # save model, optimizer, losses['train']\n    save(epoch + 1, model, optimizer, losses['train'])\n    \n    # print ('Epoch {} Loss {:.4f}'.format(epoch + 1, train_loss.result()))\n\n    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"xORKpv69dSW5","outputId":"428ae5d1-4bcb-41b2-9786-26e1b10f4d43","execution":{"iopub.status.busy":"2023-05-05T18:57:08.186802Z","iopub.execute_input":"2023-05-05T18:57:08.187160Z","iopub.status.idle":"2023-05-05T20:15:30.836693Z","shell.execute_reply.started":"2023-05-05T18:57:08.187132Z","shell.execute_reply":"2023-05-05T20:15:30.835515Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"step 0: train loss 5.5495\nstep 500: train loss 5.3065\nstep 1000: train loss 5.1505\nstep 1500: train loss 5.0089\nTime taken for 1 epoch: 942.272579908371 secs\n\nstep 0: train loss 4.9867\nstep 500: train loss 4.8857\nstep 1000: train loss 4.7981\nstep 1500: train loss 4.7110\nTime taken for 1 epoch: 943.8305606842041 secs\n\nstep 0: train loss 4.6989\nstep 500: train loss 4.5986\nstep 1000: train loss 4.5342\nstep 1500: train loss 4.5063\nTime taken for 1 epoch: 940.857351064682 secs\n\nstep 0: train loss 4.4796\nstep 500: train loss 4.4115\nstep 1000: train loss 4.3793\nstep 1500: train loss 4.3147\nTime taken for 1 epoch: 938.5788416862488 secs\n\nstep 0: train loss 4.3240\nstep 500: train loss 4.2882\nstep 1000: train loss 4.2649\nstep 1500: train loss 4.2034\nTime taken for 1 epoch: 937.0985174179077 secs\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Inference","metadata":{"id":"PVbEUCZagJ0G"}},{"cell_type":"markdown","source":"#### Predicting one word at a time at the decoder and appending it to the output; then taking the complete sequence as an input to the decoder and repeating until maxlen or stop keyword appears","metadata":{"id":"YMbqGTixu1cl"}},{"cell_type":"code","source":"decoder_input = tokenizer.encode('[CLS]', add_special_tokens=False)  # will be list of 1 \n# convert it to a tensor and add new dimension to be like batchsize of 1 and sequence\noutput = torch.tensor(decoder_input, device=device).unsqueeze(0)\n","metadata":{"id":"TGnDibqx8JyZ","execution":{"iopub.status.busy":"2023-05-05T20:16:12.672486Z","iopub.execute_input":"2023-05-05T20:16:12.672843Z","iopub.status.idle":"2023-05-05T20:16:12.680197Z","shell.execute_reply.started":"2023-05-05T20:16:12.672816Z","shell.execute_reply":"2023-05-05T20:16:12.679198Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# turn of grad while evaluaring model\n@torch.no_grad()\ndef evaluate(input_document):\n  \n    # let model be in evaluation phase so layers like normalization, .. change their behaviour at inference time\n    model.eval()\n    \n    # TODO:: must add add_special_tokens=False later after this session\n    input_document = torch.tensor(tokenizer.encode(input_document, truncation=\"longest_first\", padding='max_length', max_length=encoder_maxlen), device=device)\n    \n    # make it of size (1, input_document_size) to match transformers convention of (batch, input_documents_size)\n    encoder_input = input_document.unsqueeze(0)\n\n    \n    decoder_input = tokenizer.encode(\"[CLS]\", add_special_tokens=False)  # will be list of 1 \n    \n    # make it of size (1, input_document_size) to match transformers convention of (batch, input_documents_size)\n    output = torch.tensor(decoder_input, device=device).unsqueeze(0)\n    \n    for i in range(decoder_maxlen):\n        encoder_mask, decoder_mask = create_masks(encoder_input, output)\n        \n        logits, _ = model(encoder_input, encoder_mask, output, None, decoder_mask)\n        # in this case : logits size (B,T,vocab_size)\n        \n        # predictions, attention_weights = transformer(\n        #     encoder_input, \n        #     output,\n        #     False,\n        #     enc_padding_mask,\n        #     combined_mask,\n        #     dec_padding_mask\n        # )\n\n        logits = logits[: ,-1:, :]\n        predicted_id = torch.argmax(logits, dim=-1)\n\n        if predicted_id == tokenizer.sep_token_id:\n            return output\n\n        output = torch.cat((output, predicted_id), dim=-1)\n\n    return output\n","metadata":{"id":"F5D5cv2Jd8-6","execution":{"iopub.status.busy":"2023-05-05T20:16:15.726219Z","iopub.execute_input":"2023-05-05T20:16:15.726582Z","iopub.status.idle":"2023-05-05T20:16:15.734001Z","shell.execute_reply.started":"2023-05-05T20:16:15.726554Z","shell.execute_reply":"2023-05-05T20:16:15.733069Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"def summarize(input_document):\n    # not considering attention weights for now, can be used to plot attention heatmaps in the future\n    summarized = evaluate(input_document=input_document)\n    return tokenizer.decode(summarized.view(-1))","metadata":{"id":"UkpdiW6wnmiS","execution":{"iopub.status.busy":"2023-05-05T20:16:16.958769Z","iopub.execute_input":"2023-05-05T20:16:16.960729Z","iopub.status.idle":"2023-05-05T20:16:16.965389Z","shell.execute_reply.started":"2023-05-05T20:16:16.960684Z","shell.execute_reply":"2023-05-05T20:16:16.964468Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"for i in range(2):\n  # generate a random number between low and high\n  index = random.uniform(0, len(document))//1\n  print(\"index: \",index)\n  print(\"Document: \\n\",document[index])\n  print(\"Real Summary: \\n\", summary[index])\n  print(\"Model Summary: \\n\", summarize(document[index]))\n  print(\"--------------------------------------\\n\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kNVOWPXFIn0k","outputId":"e25fc9c5-5be9-4b16-869f-9b3fe821f92b","execution":{"iopub.status.busy":"2023-05-05T20:19:32.749481Z","iopub.execute_input":"2023-05-05T20:19:32.750037Z","iopub.status.idle":"2023-05-05T20:19:33.952553Z","shell.execute_reply.started":"2023-05-05T20:19:32.750006Z","shell.execute_reply":"2023-05-05T20:19:33.951470Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"index:  31580.0\nDocument: \n CNN  For years the message was simple Use condoms to prevent HIV But if you are at high risk of contracting the virus health experts want you to consider an additional strategy  taking a pill every day to reduce your chance of being infected New guidelines published by the Centers for Disease Control and Prevention say preexposure prophylaxis or PrEP should be taken daily by people who are at high risk for contracting HIV The recommendation is based on several large national and international studies which were done in varying atrisk populations such as gay and bisexual men heterosexual couples where one person is HIVpositive the other is not and injection drug users The studies all showed that this drug can help reduce infection rates by more than 90 when taken daily While a vaccine or cure may one day end the HIV epidemic PrEP is a powerful tool that has the potential to alter the course of the US HIV epidemic today DrJonathan Mermin director of the CDC's National Center for HIVAIDS Viral Hepatitis STD and TB Prevention said in a statement These guidelines represent an important step toward fully realizing the promise of PrEP We should add to this momentum working to ensure that PrEP is used by the right people in the right way in the right circumstances According to the guidelines those circumstances would be anyone who  • has had sex without a condom  • is not infected with HIV but is in a sexual relationship with an HIVinfected partner  • is a gay or bisexual man who has had a sexually transmitted disease within the last six months and is not in a mutually exclusive relationship with a recently tested HIVnegative partner  • is a heterosexual man or woman who does not always use condoms when having sex with partners already at risk and who isn't in a mutually exclusive relationship with a recently tested HIVnegative partner  or  • has injected drugs or shared drug paraphernalia in the past six months  In 22 the Food and Drug Administration approved Truvada a pill that combines two antiretroviral drugs for the prevention of HIV It was first approved in 24 as an HIV treatment and is still the only FDAapproved medication for PrEP Truvada isn't cheap A month's supply can cost you anywhere from 10 to 10 according to Drugscom But insurance may cover the bill To be effective this pill must be taken every day Dr Anthony Fauci an immunologist who has been at the forefront of HIVAIDS research for decades called it a highly effective approach to preventing the spread of the virus that causes AIDS It's one that benefits not only the individual patient at risk for HIV infection but also will help to reduce the number of new HIV infections across the United States said Fauci director of the National Institute of Allergy and Infectious Diseases at the National Institutes of Health It should be used together with  and complementary to  condoms and not as a substitute for condoms The new guidelines replace interim ones published two years ago they provide a comprehensive place where doctors and patients can find information on PrEP and come with a supplement that provides checklists for physicians giving them stepbystep support for dealing with patients who might be considered for prophylactic treatment PrEP is a new approach to HIV prevention that requires continuing collaboration between patients and providers as effectiveness requires adherence to daily medication and regular medical visits for monitoring counseling and testing said Dr Dawn K Smith an epidemiologist in CDC's Division of HIVAIDS Prevention who led the development of the guidelines Individuals will have to decide with their doctor if PrEP is right for them but for some this may offer a muchneeded strategy to help protect themselves from HIV infection There are 11 million people in the United States living with HIV according to the CDC An estimated nearly one in six do not know they're infected Men who have sex with men are the hardest hit  while they make up 2 of the US population they account for 63 of all new infections each year according to the CDC Heterosexuals make up 25 of all new annual infections 9 are injection drug users HIV infection is preventable yet every year we see some 50 new HIV infections in the United States said Dr Tom Frieden the CDC's director in a statement PrEP used along with other prevention strategies has the potential to help atrisk individuals protect themselves and reduce new HIV infections in the United States\nReal Summary: \n [CLS] CDC recommends atrisk groups take Truvada daily to prevent HIV infection Studies show pill can help reduce infection rates by more than 90 when taken daily Health experts say they hope this will alter the course of the US HIV epidemic [SEP]\nModel Summary: \n [CLS] The Centers is a new study of HIVAIDS in the United States The CDC is a new initiative to prevent HIV infections in the US\n--------------------------------------\n\nindex:  99900.0\nDocument: \n By  Damien Gayle  In  rehab  Documents said to be Formula One legend Michael Schumacher’s medical notes have been stolen according to his manager  French police investigating the theft  of Michael Schumacher's hospital notes have asked for help from their  Swiss and German counterparts after emails sent by the thieves were  traced to Zurich The  request by a French prosecutor comes after emails sent to news  organisations offering to sell the notes were tracked to an Internet  Protocol IP address in Switzerland's biggest city The  emails signed Kagemusha which is Japanese for 'shadow warrior' offer  the notes from Schumacher's nearly sixmonth stay in Grenoble Hospital  after a nearly fatal skiiing accident left him in a coma The thieves were asking for 40 euros £30 50 for the dossier The  Local reports that the documents stolen over a week ago comprise 11  or 12 pages of notes made by a doctor during the former racing driver's  treatment A Grenoble prosecutor announced the request for help yesterday Swiss  media reported the tracking of the thieves' IP address across the  border to Switzerland but French officials would not comment on the  claim according to The Local Each  connection to the Internet has a unique IP address which can be traced  to a specific location However services do exist which allow Internet  users to hide their true location by masquerading as a different  address The latest  developments come after Schumacher's manager Sabine Kehm threatened  legal action if any of her client's medical information was made public She  said last week  'For several days stolen documents and data are being  offered for sale The offerer claims them to be the medical file of  Michael Schumacher 'We  cannot judge if these documents are authentic However the documents  are clearly stolen The theft has been reported The authorities are  involved 'We expressly  advise that both the purchase and the publication of such documents and  data is forbidden The contents of any medical files are totally private  and confidential and must not made available to the public 'We  will therefore in every single case press for criminal charges and  damages against any publication of the content or reference to the  medical file We trust for your understanding' Scroll down for video  The  University Hospital of the Canton of Vaud CHUV in Lausanne where  Schumacher was transferred from a French hospital to begin a lengthy  rehabilitation regime after his terrible skiing accident left him in a  coma  It  is 26 weeks since Schumacher was left in a coma after suffering his a  serious brain injury while skiing offpiste with his son He was  holidaying with family and friends in Meribel where he owns a chalet There  were claims he had his eyes and was conscious as he was transferred  from Grenoble to University Hospital Lausanne Switzerland on June 16  to begin his rehabilitation It was said that Schumacher 45 was able to communicate to ambulance staff by nodding his head The  report in the Swiss tabloid Blick stated that the ambulance was  operated by Sanitätoberwallis a company based in Visp in the canton of  Valais rather than from Grenoble or Lausanne Ambulance  staff were not told the identity of the worldfamous patient in  advance They also had to relinquish their mobile phones on arrival at  Grenoble Matthias Volken  medical superintendent of the ambulance firm said 'I can confirm that  we carried out the drive to transfer Schumacher on Monday' The paper said Schumacher had lost a lot of weight during his 10 days in hospital since the accident The hospital where he is now being treated is one of Switzerland’s best and has renowned neurology experts\nReal Summary: \n [CLS] IP address used to send the emails to newspapers tracked to Swiss city Thieves have asked for 40 euros for the sale of the dossier Schumacher's manager has threatened legal action if it is published  [SEP]\nModel Summary: \n [CLS] Michael Schumacher's manager says he was'devastated'by the French's company's manager says it's not apologised for the company's company's claims of the theft of the's medical treatment\n--------------------------------------\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# test load \nmodel, optimizer, epoch, loss = load()","metadata":{"id":"gNpFjTgdGZPT","execution":{"iopub.status.busy":"2023-05-05T18:36:29.773230Z","iopub.status.idle":"2023-05-05T18:36:29.780029Z","shell.execute_reply.started":"2023-05-05T18:36:29.779850Z","shell.execute_reply":"2023-05-05T18:36:29.779869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(loss, epoch)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6oSyIpmSYfz-","outputId":"dcbaed8f-6247-46cf-baba-3373d92a408d","execution":{"iopub.status.busy":"2023-05-05T18:36:29.781108Z","iopub.status.idle":"2023-05-05T18:36:29.781578Z","shell.execute_reply.started":"2023-05-05T18:36:29.781323Z","shell.execute_reply":"2023-05-05T18:36:29.781354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"83o56VqqYzPn"},"execution_count":null,"outputs":[]}]}